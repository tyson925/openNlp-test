



<ENAMEX TYPE="ORGANIZATION">United States General Accounting Office</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>
<TIMEX TYPE="DATE">October 2002</TIMEX> <ENAMEX TYPE="PRODUCT">External Version 1</ENAMEX>


Assessing the <ENAMEX TYPE="ORGANIZATION">Reliability of Computer-Processed Data</ENAMEX>
a
Contents
Preface
<ENAMEX TYPE="LANGUAGE">Section 1</ENAMEX>: <ENAMEX TYPE="ORGANIZATION">Introduction</ENAMEX>
<ENAMEX TYPE="LANGUAGE">Section 2</ENAMEX>: <ENAMEX TYPE="ORGANIZATION">Understanding Data</ENAMEX> Reliability

Assessment
Page i <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>-<NUMEX TYPE="CARDINAL">03</NUMEX>-273G <ENAMEX TYPE="PERSON">Assessing Reliabillity</ENAMEX>
23
<ENAMEX TYPE="LANGUAGE">Section 8</ENAMEX>: Conducting

Tracing to and from <ENAMEX TYPE="ORGANIZATION">Source</ENAMEX>
Documents <ENAMEX TYPE="WORK_OF_ART">24 Using Advanced Electronic Testing 25 Reviewing</ENAMEX>
<ENAMEX TYPE="WORK_OF_ART">Selected System Controls 26 Using Data of Undetermined</ENAMEX> Reliability
27
28
<ENAMEX TYPE="LANGUAGE">Section 9</ENAMEX>: <ENAMEX TYPE="WORK_OF_ART">Making the</ENAMEX>

<ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data 29</ENAMEX> Not
<ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data 29 Data</ENAMEX> of <ENAMEX TYPE="PERSON">Undetermined Reliability</ENAMEX>
30
31
<ENAMEX TYPE="LAW">Section 10</ENAMEX>: Including

<ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data</ENAMEX> 31
Not <ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data</ENAMEX> <NUMEX TYPE="MONEY">31</NUMEX> in the <ENAMEX TYPE="ORGANIZATION">Report Data</ENAMEX> of
<ENAMEX TYPE="PERSON">Undetermined Reliability</ENAMEX> <NUMEX TYPE="CARDINAL">32</NUMEX>
Glossary of <ENAMEX TYPE="ORGANIZATION">Technical Terms</ENAMEX>
Figure <NUMEX TYPE="CARDINAL">1</NUMEX>:
Figures
Figure <NUMEX TYPE="CARDINAL">2</NUMEX>:
Figure <NUMEX TYPE="CARDINAL">3</NUMEX>: Figure <NUMEX TYPE="CARDINAL">4</NUMEX>: Figure <NUMEX TYPE="CARDINAL">5</NUMEX>: Figure <NUMEX TYPE="CARDINAL">6</NUMEX>: Figure <NUMEX TYPE="CARDINAL">7</NUMEX>: Factors to
Consider in <ENAMEX TYPE="WORK_OF_ART">Making the Decision on Using the Data 1 Decision</ENAMEX>
Process for Determining If a <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment</ENAMEX> Is
Required <ENAMEX TYPE="ORGANIZATION">7 Data Reliability Assessment</ENAMEX> Process <NUMEX TYPE="CARDINAL">13</NUMEX> The <NUMEX TYPE="ORDINAL">First</NUMEX> Steps
of the <ENAMEX TYPE="WORK_OF_ART">Assessment 14 The Preliminary Assessment 19 Choosing and</ENAMEX>
<ENAMEX TYPE="WORK_OF_ART">Conducting Additional Work 23 Making the Final Assessment 28</ENAMEX>

Preface
Computer-processed data, often from external <ENAMEX TYPE="PER_DESC">sources</ENAMEX>,
increasingly underpin audit reports, including evaluations
(performance audits) and financial audits. Therefore, the
reliability of such data has become more and more important.
Historically, computer-processed data have been treated as unique
evidence. However, these data are simply one form of evidence
relied on, although they may require more technical assessment than
other forms of evidence. In addition, the very nature of the
information system creating the data allows opportunities for
errors to be introduced by many <ENAMEX TYPE="PER_DESC">people</ENAMEX>.
This guidance is intended to demystify the assessment of
computerprocessed data. It supplements <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s "<ENAMEX TYPE="WORK_OF_ART">Yellow Book</ENAMEX>"
(<ENAMEX TYPE="ORGANIZATION">Government Auditing Standards</ENAMEX>, <TIMEX TYPE="DATE">1994</TIMEX> <ENAMEX TYPE="ORGANIZATION">Revision</ENAMEX>), which defines the
generally accepted government auditing standards (GAGAS), and
replaces the earlier <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> guidance, <ENAMEX TYPE="WORK_OF_ART">Assessing the Reliability of</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Computer-Processed Data</ENAMEX> (<ENAMEX TYPE="ORGANIZATION">GAO/OP</ENAMEX>-<NUMEX TYPE="CARDINAL">8.1.3</NUMEX>, <TIMEX TYPE="DATE">Sept. 1990</TIMEX>).
For all types of evidence, various tests are used-sufficiency,
<ENAMEX TYPE="PERSON">competence</ENAMEX>, and relevance-to assess whether the evidence standard
is met. You probably have been using these tests for <TIMEX TYPE="DATE">years</TIMEX> and have
become quite proficient at them. But because assessing
computer-processed data requires more technical tests, it may
appear that such data are subject to a higher standard of testing
than other evidence. That is not the case. For example, many of the
same tests of sufficiency and relevance are applied to other types
of evidence. But in assessing computer-processed data, the focus is
on <NUMEX TYPE="CARDINAL">one</NUMEX> test in the evidence standard-competence-which includes
validity and reliability. Reliability, in turn, includes the
<ENAMEX TYPE="PERSON">completeness</ENAMEX> and accuracy of the data.
This guidance, therefore, provides a flexible, risk-based
framework for data reliability assessments that can be geared to
the specific circumstances of each engagement. The framework also
provides a <ENAMEX TYPE="FAC_DESC">structure</ENAMEX> for planning and reporting, facilitates
bringing the right mix of skills to each engagement, and ensures
timely <ENAMEX TYPE="PER_DESC">management</ENAMEX> buy-in on assessment strategies. The framework is
built on


•
making use of all existing information about the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>,


•
performing at least a minimal level of data
testing,


•
doing only the amount of work necessary to determine
whether the data are reliable enough for our purposes,


•
maximizing professional judgment, and


•
bringing the appropriate <ENAMEX TYPE="PER_DESC">people</ENAMEX>, including <ENAMEX TYPE="PER_DESC">management</ENAMEX>, to
the table at key decision points.


The ultimate goal of the data reliability assessment is to
determine whether you can use the data for your intended purposes.
This guidance is designed to help you make an appropriate,
defensible assessment in the most efficient manner. With any
related questions, call <ENAMEX TYPE="PERSON">Barbara Johnson</ENAMEX>, focal point for data
reliability issues, at (<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <TIMEX TYPE="DATE">512-3663</TIMEX>, or <ENAMEX TYPE="PERSON">Barry Seltser</ENAMEX>, the Acting
<ENAMEX TYPE="PER_DESC">Director</ENAMEX> of <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s <ENAMEX TYPE="ORGANIZATION">Center for Design</ENAMEX>, <ENAMEX TYPE="PERSON">Methods</ENAMEX>, and <ENAMEX TYPE="ORGANIZATION">Analysis</ENAMEX>, at
(<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <ENAMEX TYPE="CONTACT_INFO">512-3234</ENAMEX>.

<ENAMEX TYPE="PERSON">Nancy Kingsbury</ENAMEX>
Managing <ENAMEX TYPE="PER_DESC">Director</ENAMEX>, <ENAMEX TYPE="ORGANIZATION">Applied Research and Methods</ENAMEX>
<ENAMEX TYPE="LANGUAGE">Section 1</ENAMEX>: <ENAMEX TYPE="ORGANIZATION">Introduction</ENAMEX>
This guidance explains what data reliability means and provides
a framework for assessing the reliability of computer-processed
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>. It begins with the steps in a preliminary assessment, which,
in many cases, may be all you need to do to assess reliability.
This guidance also helps you decide whether you should follow up
the preliminary assessment with additional work. If so, it explains
the steps in a final assessment and the actions to take, depending
on the results of your additional work. The ultimate goal in
determining data reliability is to make the following decision: For
our engagement, can we use the data to answer the research
question? See figure <NUMEX TYPE="CARDINAL">1</NUMEX> for an overview of the factors that help to
inform that decision. Not all of these factors may be necessary for
all engagements.
Figure <NUMEX TYPE="CARDINAL">1</NUMEX>: <ENAMEX TYPE="WORK_OF_ART">Factors to Consider in Making the Decision on Using</ENAMEX>
the <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
In addition, this guidance discusses suggested
language-appropriate under different circumstances-for reporting
the results of your assessment. Finally, it provides detailed
descriptions of all the stages of the assessment, as well as a
glossary of technical terms used (see <ENAMEX TYPE="PERSON">p.</ENAMEX> <NUMEX TYPE="CARDINAL">33</NUMEX>). An on-line version of
this guidance, which will include tools that may help you in
assessing reliability, is currently being developed. The overall
process is illustrated in figures 2 (<ENAMEX TYPE="CONTACT_INFO">p. 7</ENAMEX>) and <NUMEX TYPE="CARDINAL">3</NUMEX> (<ENAMEX TYPE="CONTACT_INFO">p. 13</ENAMEX>).
<ENAMEX TYPE="LANGUAGE">Section 2</ENAMEX>: <ENAMEX TYPE="ORGANIZATION">Understanding Data</ENAMEX> Reliability
<ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> reliability refers to the accuracy and completeness of
computerprocessed data, given the intended purposes for use.
Computer-processed data include data (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) entered into a computer
<ENAMEX TYPE="ORGANIZATION">system</ENAMEX> and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) resulting from computer processing.
Computer-processed data can vary in form-from electronic files to
tables in published reports. The definition of computerprocessed
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> is therefore broad. In this guidance, the term data always
refers to computer-processed data.
The "<ENAMEX TYPE="WORK_OF_ART">Yellow Book</ENAMEX>" requires that a data reliability assessment be
performed for all data used as support for engagement findings,
<ENAMEX TYPE="PERSON">conclusions</ENAMEX>, or recommendations<NUMEX TYPE="CARDINAL">.1</NUMEX> This guidance will help you to
design a data reliability assessment appropriate for the purposes
of the engagement and then to evaluate the results of the
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>.
<ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> are reliable when they are (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) complete (they contain all
of the data elements and records needed for the engagement)<NUMEX TYPE="CARDINAL">2</NUMEX> and
(<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) accurate (they reflect the data entered at the <ENAMEX TYPE="ORG_DESC">source</ENAMEX> or, if
available, in the source documents). A subcategory of accuracy is
<ENAMEX TYPE="PERSON">consistency</ENAMEX>. Consistency refers to the need to obtain and use data
that are clear and well-defined enough to yield similar results in
similar analyses. For example, if data are entered at multiple
sites, inconsistent interpretation of data rules can lead to data
that, taken as a whole, are unreliable. <ENAMEX TYPE="ORGANIZATION">Reliability</ENAMEX> also means that
for any computer processing of the data elements used, the results
are reasonably complete and accurate, meet your intended purposes,
and are not subject to inappropriate alteration.
Assessments of reliability should be made in the broader context
of the particular characteristics of the engagement and the risk
<ENAMEX TYPE="ORGANIZATION">associated</ENAMEX> with the possibility of using data of insufficient
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX>. <ENAMEX TYPE="ORGANIZATION">Reliability</ENAMEX> does not mean that computer-processed data
are error-free. Errors are considered acceptable under these
circumstances: You have assessed the associated risk and found the
errors are not significant enough to cause a reasonable <ENAMEX TYPE="PER_DESC">person</ENAMEX>,
aware of the errors, to doubt a finding, conclusion, or
recommendation based on the data.
1U.<ENAMEX TYPE="ORGANIZATION">S. General Accounting Office</ENAMEX>, <ENAMEX TYPE="ORGANIZATION">Government Auditing Standards</ENAMEX>, 
<ENAMEX TYPE="ORGANIZATION">GAO/OGC</ENAMEX>-<NUMEX TYPE="CARDINAL">94</NUMEX>-4(<ENAMEX TYPE="GPE">Washington</ENAMEX>, <ENAMEX TYPE="GPE">D.C.</ENAMEX>: <TIMEX TYPE="DATE">June 1994</TIMEX>), pp.
<NUMEX TYPE="CARDINAL">62-87</NUMEX>.
2A data element is a <ENAMEX TYPE="ORG_DESC">unit</ENAMEX> of information with definable
<ENAMEX TYPE="PERSON">parameters</ENAMEX> (for example, a <ENAMEX TYPE="ORGANIZATION">Social Security</ENAMEX> number), sometimes
referred to as a data variable or data field.
Page <NUMEX TYPE="CARDINAL">3</NUMEX> <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>-<NUMEX TYPE="CARDINAL">03</NUMEX>-273G <ENAMEX TYPE="PERSON">Assessing Reliability</ENAMEX>
While this guidance focuses only on the reliability of data in
terms of accuracy and completeness, other data quality
considerations are just as important. In particular, you should
also consider the validity of data. <ENAMEX TYPE="PERSON">Validity</ENAMEX> (as used here) refers
to whether the data actually represent what you think is being
measured. For example, if a data field is named "<TIMEX TYPE="DATE">annual</TIMEX> evaluation
score," is this an appropriate measure of a <ENAMEX TYPE="PER_DESC">person</ENAMEX>'s job
performance? Considerations of data validity and reliability issues
should be addressed early in the engagement, and appropriate
technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX>-such as data <ENAMEX TYPE="PER_DESC">analysts</ENAMEX>, <ENAMEX TYPE="PER_DESC">statisticians</ENAMEX>, or
information technology <ENAMEX TYPE="ORG_DESC">specialists</ENAMEX>-should be consulted.


<ENAMEX TYPE="LANGUAGE">Section 3</ENAMEX>: Deciding If a <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment</ENAMEX> Is
Necessary
To decide if a data reliability assessment is necessary, you
should consider certain conditions. The engagement type and planned
use of the data help to determine when you should assess data
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX>. See figure <NUMEX TYPE="CARDINAL">2</NUMEX> for an illustration of the decision
process that you should use.
Figure <NUMEX TYPE="CARDINAL">2</NUMEX>: <ENAMEX TYPE="WORK_OF_ART">Decision Process for Determining</ENAMEX> If a Data Reliability
Assessment Is Required

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
Conditions Requiring a <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment</ENAMEX>
You should assess reliability if the data to be analyzed are
intended to support the engagement findings, conclusions, or
recommendations. Keep in mind that a finding may include only a
description of the condition, as in a purely descriptive report. In
the audit plan for the engagement, you should include a brief
discussion of how you plan to assess data reliability, as well as
any limitations that may exist due to shortcomings in the data.
Conditions Not Requiring a <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment</ENAMEX>
You do not need to assess reliability if the data are used (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>)
only as background information or (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) in documents without
findings, conclusions, or recommendations. Background information
generally sets the stage for reporting the results of an engagement
or provides information that puts the results in proper context.
Such information could be the size of the program or activity you
are reviewing, for example. When you gather background or other
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>, ensure that they are from the best available <ENAMEX TYPE="GPE_DESC">source</ENAMEX>(s). When
you present the data, cite the <ENAMEX TYPE="PER_DESC">source</ENAMEX>(s) and state that the data
were not assessed.
Sometimes, as a best practice, however, you may want to do some
assessment of background data. Your judgment of the data's
importance and the reliability of the <ENAMEX TYPE="ORG_DESC">source</ENAMEX>, as well as other
engagement factors, can help you determine the extent of such an
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>.
Finally, for financial audits and information system reviews,
you should not follow this guidance in assessing data reliability.
For financial audits, which include financial statement and
<ENAMEX TYPE="ORGANIZATION">financial-related</ENAMEX> audits, you should follow the <ENAMEX TYPE="ORGANIZATION">GAO/PCIE Financial</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Audit Manual</ENAMEX> (FAM) and the <ENAMEX TYPE="ORGANIZATION">Federal Information System Controls</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Audit Manual</ENAMEX> (FISCAM). In an information system review, all
controls in a computer system, for the full range of application
functions and products, are assessed and tested. Such a review
includes (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) examining the general and application controls of a
computer system<NUMEX TYPE="MONEY">,3</NUMEX> (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) testing whether those controls are being
complied with, and
(<ENAMEX TYPE="CONTACT_INFO">3</ENAMEX>) testing data produced by the system.4 To design such a
<ENAMEX TYPE="ORGANIZATION">review</ENAMEX>, appropriate to the research question, seek assistance from
information technology <ENAMEX TYPE="ORG_DESC">specialists</ENAMEX>.
3General controls refers to the structure, policies, and
procedures-which apply to all or a large segment of an
<ENAMEX TYPE="ORGANIZATION">organization</ENAMEX>'s information systems-that help to ensure proper
operation, data integrity, and security. Application controls
refers to the structure, policies, and procedures that apply to
individual application systems, such as inventory or payroll.
4Guidance for carrying out reviews of general and application
controls is provided in the
<ENAMEX TYPE="ORGANIZATION">U.S. General Accounting Office</ENAMEX>, <ENAMEX TYPE="ORGANIZATION">Federal Information System</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Controls Audit Manual</ENAMEX>, 
<ENAMEX TYPE="ORGANIZATION">GAO/AIMD</ENAMEX>-<NUMEX TYPE="CARDINAL">12.19.6</NUMEX>(<ENAMEX TYPE="GPE">Washington</ENAMEX>, <ENAMEX TYPE="GPE">D.C.</ENAMEX>: <TIMEX TYPE="DATE">Jan. 1999</TIMEX>).


<ENAMEX TYPE="LANGUAGE">Section 4</ENAMEX>: Performing a <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment</ENAMEX>
Timing the <ENAMEX TYPE="ORGANIZATION">Assessment</ENAMEX>
To perform a data reliability assessment, you need to decide on
the timing-when to perform the assessment-and how to document
it.
A data reliability assessment should be performed as early as
possible in the engagement process, preferably during the design
phase. The audit plan should reflect data reliability issues and
any additional steps that still need to be performed to assess the
reliability of critical data. The engagement <ENAMEX TYPE="PER_DESC">team</ENAMEX> generally should
not finalize the audit plan or issue a commitment letter until it
has done initial testing and reviewed existing information about
the data and the system that produces the data. In addition, the
<ENAMEX TYPE="ORGANIZATION">team</ENAMEX> should not commit to making conclusions or recommendations
based on the data unless the <ENAMEX TYPE="ORG_DESC">team</ENAMEX> expects to be satisfied with the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> reliability.
Documenting the <ENAMEX TYPE="ORGANIZATION">Assessment</ENAMEX>
All work performed as part of the data reliability assessment
should be documented and included in the engagement workpapers.
This includes all testing, information review, and interviews
related to data reliability. In addition, decisions made during the
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>, including the final assessment of whether the data are
sufficiently reliable for the purposes of the engagement, should be
<ENAMEX TYPE="PERSON">summarized</ENAMEX> and included with the workpapers. These workpapers
should be (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) clear about what steps the <ENAMEX TYPE="ORG_DESC">team</ENAMEX> took and what
conclusions they reached and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) reviewed by <ENAMEX TYPE="PER_DESC">staff</ENAMEX> with appropriate
<ENAMEX TYPE="PRODUCT">skills</ENAMEX> or, if needed, technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX>.


<ENAMEX TYPE="LANGUAGE">Section 5</ENAMEX>: <ENAMEX TYPE="WORK_OF_ART">Viewing the Entire Assessment Process</ENAMEX>
The ultimate goal of the data reliability assessment is to
determine whether you can use the data to answer the research
question. The assessment should be performed only for those
portions of the data that are relevant to the engagement. The
extensiveness of the assessment is driven by


•
the expected significance of the data to the final
<ENAMEX TYPE="ORGANIZATION">report</ENAMEX>,


•
the anticipated risk level of using the data,
and


•
the strength or weakness of any corroborating
evidence.


Therefore, the specific assessment process should take into
account these factors along with what is learned during the initial
stage of the assessment. The process is likely to be different for
each engagement.
The overall framework of the process for data reliability
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX> is shown in figure <NUMEX TYPE="CARDINAL">3</NUMEX>. The framework identifies several
key stages in the assessment, as well as actions and decisions
expected as you move through the process. The framework allows you
to identify the appropriate mix of assessment steps to fit the
particular needs of your engagement. In most cases, all of the
<ENAMEX TYPE="PER_DESC">elements</ENAMEX> in figure <NUMEX TYPE="CARDINAL">3</NUMEX> would not be necessary in completing the
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>. Specific actions for each <ENAMEX TYPE="FAC_DESC">stage</ENAMEX> are discussed in
<ENAMEX TYPE="CONTACT_INFO">sections 6-10</ENAMEX>.
Figure <NUMEX TYPE="CARDINAL">3</NUMEX>: <ENAMEX TYPE="ORGANIZATION">Data Reliability Assessment Process</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.


<ENAMEX TYPE="LANGUAGE">Section 6</ENAMEX>: Taking the <NUMEX TYPE="ORDINAL">First</NUMEX> Steps
Reviewing <ENAMEX TYPE="ORGANIZATION">Existing Information</ENAMEX>
The data reliability process begins with <NUMEX TYPE="CARDINAL">two</NUMEX> relatively simple
steps. These steps provide the basis for making a preliminary
assessment of data reliability: (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) a review of related information
and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) initial testing (see figure <NUMEX TYPE="CARDINAL">4</NUMEX>). In some situations, you may
have an extremely short time frame for the engagement; this section
also provides some advice for this situation.
The time required to review related information and perform
initial testing will vary, depending on the engagement and the
amount of risk involved. As discussed in <ENAMEX TYPE="LAW">section 4</ENAMEX>, these steps
should take place early in the engagement and include the team
<ENAMEX TYPE="PER_DESC">members</ENAMEX>, as well as appropriate technical <ENAMEX TYPE="PER_DESC">staff</ENAMEX>.
Figure <NUMEX TYPE="CARDINAL">4</NUMEX>: The <NUMEX TYPE="ORDINAL">First</NUMEX> Steps of the <ENAMEX TYPE="ORGANIZATION">Assessment</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
The <NUMEX TYPE="ORDINAL">first</NUMEX> step-a review of existing information-helps you to
determine what is already known about the data and the computer
processing. The related information you collect can indicate both
the accuracy and completeness of the entry and processing of the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>, as well as how data integrity is maintained. This information
can be in the form of reports, studies, or interviews with
<ENAMEX TYPE="PER_DESC">individuals</ENAMEX> who are knowledgeable about the data and the system.
<ENAMEX TYPE="PER_DESC">Sources</ENAMEX> for related information include <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>, the <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> under
<ENAMEX TYPE="ORGANIZATION">review</ENAMEX>, and others.
<ENAMEX TYPE="ORGANIZATION">GAO GAO</ENAMEX> may already have related information in reports. Those
from <TIMEX TYPE="DATE">fiscal year 1995</TIMEX> to the present are available via <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s
Internet site. This site also provides other useful information:
for example, as part of the <TIMEX TYPE="DATE">annual</TIMEX> governmentwide consolidated
financial audit, <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s <ENAMEX TYPE="ORGANIZATION">Information Technology Team</ENAMEX> is involved with
reporting on the effectiveness of controls for financial
information systems at <NUMEX TYPE="CARDINAL">24</NUMEX> major federal <ENAMEX TYPE="ORG_DESC">agencies</ENAMEX>.
<ENAMEX TYPE="ORGANIZATION">Agency</ENAMEX> under <ENAMEX TYPE="ORGANIZATION">Review</ENAMEX>
<ENAMEX TYPE="PER_DESC">Officials</ENAMEX> of the <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> or <ENAMEX TYPE="ORG_DESC">entity</ENAMEX> under review are aware of
evaluations of their computer data or systems and usually can
direct you to both. However, keep in mind that information from
<ENAMEX TYPE="ORGANIZATION">agency</ENAMEX> <ENAMEX TYPE="PER_DESC">officials</ENAMEX> may be biased. Consider asking appropriate
technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX> to help in evaluating this information.
<ENAMEX TYPE="ORGANIZATION">Agency</ENAMEX> information includes <ENAMEX TYPE="PER_DESC">Inspector General</ENAMEX> reports, <ENAMEX TYPE="ORGANIZATION">Federal</ENAMEX>
<ENAMEX TYPE="PER_DESC">Managers</ENAMEX>' <ENAMEX TYPE="LAW">Financial Integrity Act</ENAMEX> reports, <ENAMEX TYPE="ORGANIZATION">Government Performance</ENAMEX>
and <ENAMEX TYPE="LAW">Results Act</ENAMEX> (GPRA) plans and reports, <ENAMEX TYPE="PERSON">Clinger-Cohen</ENAMEX> Act
reports, and Chief <ENAMEX TYPE="ORGANIZATION">Information</ENAMEX> <ENAMEX TYPE="PER_DESC">Officer</ENAMEX> reports. (Some of this
information can be found in <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> homepages on the Web.)
Others Other <ENAMEX TYPE="ORG_DESC">organizations</ENAMEX> and <ENAMEX TYPE="PER_DESC">users</ENAMEX> of the data may be sources
of relevant information. To help you identify these <ENAMEX TYPE="PER_DESC">sources</ENAMEX>, you
can use a variety of databases and other research tools, which
include the <ENAMEX TYPE="ORGANIZATION">Congressional Research Service Public Policy Literature</ENAMEX>
<ENAMEX TYPE="PERSON">Abstracts</ENAMEX> and <ENAMEX TYPE="ORG_DESC">organizations</ENAMEX>' Web sites.
Performing Initial Testing
The <NUMEX TYPE="ORDINAL">second</NUMEX> step-initial testing-can be done by applying logical
tests to electronic data files or hard copy reports. For electronic
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>, you use computer programs to test all entries of key data
<ENAMEX TYPE="PER_DESC">elements</ENAMEX> in the entire data file<NUMEX TYPE="CARDINAL">.5</NUMEX> Keep in mind that you only test
those data elements you plan to use for the engagement. You will
find that testing with computer programs often takes less than a
<ENAMEX TYPE="PERSON">day</ENAMEX>, depending on the complexity of the file. For
<NUMEX TYPE="CARDINAL">5</NUMEX> Though an in-depth discussion of quality-assurance practices
to be used in electronic testing and analyses is beyond the scope
of this guidance, it is important to perform appropriate checks to
ensure that you have obtained the correct file. All too often,
<ENAMEX TYPE="PER_DESC">analysts</ENAMEX> receive an incorrect file (an early version or an
incomplete file). Appropriate steps would include counting records
and comparing totals with the responsible <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> or <ENAMEX TYPE="ORG_DESC">entity</ENAMEX>.
Page <NUMEX TYPE="CARDINAL">15</NUMEX> <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>-<NUMEX TYPE="CARDINAL">03</NUMEX>-273G <ENAMEX TYPE="PERSON">Assessing Reliability</ENAMEX>
Dealing with <ENAMEX TYPE="PERSON">Short Time Frames</ENAMEX>
hard copy or summarized data-provided by the audited <ENAMEX TYPE="ORG_DESC">entity</ENAMEX> or
retrieved from the Internet-you can ask for the electronic data
file used to create the hard copy or summarized data. If you are
unable to obtain electronic data, use the hard copy or summarized
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> and, to the extent possible, manually apply the tests to all
instances of key data elements or, if the report or summary is
<ENAMEX TYPE="PERSON">voluminous</ENAMEX>, to a sample of them.
Whether you have an electronic data file or a hard copy report
or summary, you apply the same types of tests to the data. These
can include testing for


•
missing data, either entire records or values of key data
<ENAMEX TYPE="PER_DESC">elements</ENAMEX>;


•
the relationship of <NUMEX TYPE="CARDINAL">one</NUMEX> data element to
another;


•
values outside of a designated range; and


•
dates outside valid time frames or in an illogical
<ENAMEX TYPE="ORGANIZATION">progression</ENAMEX>.


Be sure to keep a log of your testing for inclusion in the
engagement workpapers.
In some instances, the engagement may have a time frame that is
too short for a complete preliminary assessment, for example, a
request for testimony in <TIMEX TYPE="DATE">2 weeks</TIMEX>. However, given that all
engagements are a function of time, as well as scope and resources,
limitations in one require balancing the others.
Despite a short time frame, you may have time to review existing
information and carry out testing of data that are critical for
answering a research question, for example: You can question
knowledgeable agency <ENAMEX TYPE="PER_DESC">staff</ENAMEX> about data reliability or review
existing <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> or <ENAMEX TYPE="PER_DESC">Inspector General</ENAMEX> reports to quickly gather
information about data reliability issues. In addition, electronic
testing of critical data elements for obvious errors of
<ENAMEX TYPE="PERSON">completeness</ENAMEX> and accuracy can generally be done in a short period
of time on all but the most complicated or immense files. From that
<ENAMEX TYPE="ORGANIZATION">review</ENAMEX> and testing, you will be able to make a more informed
determination about whether the data are sufficiently reliable to
use for the purposes of the engagement. (See sections <NUMEX TYPE="CARDINAL">7 and 8</NUMEX> for
the actions to take, depending on your <ENAMEX TYPE="PER_DESC">determination</ENAMEX>.)


<ENAMEX TYPE="LANGUAGE">Section 7</ENAMEX>: <ENAMEX TYPE="WORK_OF_ART">Making the Preliminary Assessment</ENAMEX>
Factors to Consider in the <ENAMEX TYPE="ORGANIZATION">Assessment</ENAMEX>
The preliminary assessment is the <NUMEX TYPE="ORDINAL">first</NUMEX> decision point in the
assessment process, including the consideration of multiple
factors, a determination of the sufficiency of the data reliability
with what is known at this point, and a decision about whether
further work is required. You will decide whether the data are
sufficiently reliable for the purposes of the engagement, not
sufficiently reliable, or as yet undetermined. Keep in mind that
you are not attesting to the overall reliability of the data or
database. You are only determining the reliability of the data as
needed to support the findings, conclusions, or recommendations of
the engagement. As you gather information and make your judgments,
consult appropriate technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX> for assistance.
To make the preliminary assessment of the sufficiency of the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> reliability for the engagement, you should consider all
factors related to aspects of the engagement, as well as assessment
work performed to this point. As shown in figure <NUMEX TYPE="CARDINAL">5</NUMEX>, these factors
include


•
the expected significance of the data in the final
<ENAMEX TYPE="ORGANIZATION">report</ENAMEX>,


•
corroborating evidence,


•
level of risk, and


•
the results of initial assessment work.


Figure <NUMEX TYPE="CARDINAL">5</NUMEX>: The <ENAMEX TYPE="ORGANIZATION">Preliminary Assessment</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
Expected <ENAMEX TYPE="LAW">Significance</ENAMEX> of In making the preliminary assessment,
consider the data in the context of the final report: Will the
engagement team depend on the data alone to
the <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> in the <ENAMEX TYPE="WORK_OF_ART">Final Report</ENAMEX>
answer a research question? Will the data be summarized or will
detailed information be required? Is it important to have precise
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>, making magnitude of errors an issue?
Corroborating Evidence You should consider the extent to which
corroborating evidence is likely to exist and will independently
support your findings, conclusions, or recommendations.
Corroborating evidence is independent evidence that supports
information in the database. Such evidence, if available, can be
found in the form of alternative <ENAMEX TYPE="SUBSTANCE">databases</ENAMEX> or <ENAMEX TYPE="PER_DESC">expert</ENAMEX> views. It is
unique to each engagement, and its
strength-persuasiveness-varies.
For help in deciding the strength or weakness of corroborating
evidence, consider the extent to which the corroborating
evidence


•
is consistent with the "<ENAMEX TYPE="WORK_OF_ART">Yellow Book</ENAMEX>" standards of
evidence-sufficiency, competence, and relevance;


•
provides crucial support;


Level of <ENAMEX TYPE="ORGANIZATION">Risk</ENAMEX>


•
is drawn from different types of <ENAMEX TYPE="PER_DESC">sources</ENAMEX>-testimonial,
<ENAMEX TYPE="PERSON">documentary</ENAMEX>, physical, or analytical; and



•
is independent of other sources.

Risk is the likelihood that using data of questionable
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX> could have significant negative consequences on the
decisions of policymakers and others. To do a risk assessment,
consider the following risk conditions:


•
The data could be used to influence legislation, policy,
or a program that could have significant impact.


•
The data could be used for significant decisions by
<ENAMEX TYPE="PER_DESC">individuals</ENAMEX> or <ENAMEX TYPE="ORG_DESC">organizations</ENAMEX> with an interest in the
subject.


•
The data will be the basis for numbers that are likely to
be widely quoted, for example, "In <TIMEX TYPE="DATE">1999</TIMEX>, the <ENAMEX TYPE="GPE">United States</ENAMEX> owed the
<ENAMEX TYPE="ORGANIZATION">United Nations</ENAMEX> <NUMEX TYPE="MONEY">about $1.3 billion</NUMEX> for the regular and peacekeeping
budgets."


•
The engagement is concerned with a sensitive or
controversial subject.


•
The engagement has external stakeholders who have taken
positions on the subject.


•
The overall engagement risk is medium or high.


•
The engagement has unique factors that strongly increase
risk.


<ENAMEX TYPE="ORGANIZATION">Bear</ENAMEX> in mind that any one of the conditions may have more
importance than another, depending on the engagement.
Results of <ENAMEX TYPE="ORGANIZATION">Initial Assessment Work</ENAMEX>
At this point, as shown in figure <NUMEX TYPE="CARDINAL">5</NUMEX> (<ENAMEX TYPE="CONTACT_INFO">p. 19</ENAMEX>), the <ENAMEX TYPE="ORG_DESC">team</ENAMEX> will
already have performed the initial stage of the data reliability
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>. They should have the results from the (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) review of all
available existing information about the data and the system that
produced them and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) initial testing of the critical data
<ENAMEX TYPE="PER_DESC">elements</ENAMEX>. These results should be appropriately documented and
reviewed before the <ENAMEX TYPE="ORG_DESC">team</ENAMEX> enters into the decision-making phase of
the preliminary assessment. Because the results will, in whole or
in part, provide the evidence that the data are sufficiently
reliable-and therefore competent enough-or not sufficiently
reliable for the purposes
Outcomes to Consider in the <ENAMEX TYPE="ORGANIZATION">Assessment</ENAMEX>
of the engagement, the workpapers should include documentation
of the process and results.
The results of your combined judgments of the strength of
corroborating evidence and degree of risk suggest different
assessments. If the corroborating evidence is strong and the risk
is low, the data are more likely to be considered sufficiently
reliable for your purposes. If the corroborating evidence is weak
and the risk is high, the data are more likely to be considered not
sufficiently reliable for your purposes. The overall assessment is
a judgment call, which should be made in the context of discussion
with <ENAMEX TYPE="ORG_DESC">team</ENAMEX> <ENAMEX TYPE="PER_DESC">management</ENAMEX> and technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX>.
The preliminary assessment categorizes the data as sufficiently
<ENAMEX TYPE="PERSON">reliable</ENAMEX>, not sufficiently reliable, or of undetermined
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX>. Each category has implications for the next steps of
the data reliability assessment.
When <ENAMEX TYPE="WORK_OF_ART">to Assess Data as Sufficiently Reliable for Engagement</ENAMEX>
Purposes
You can assess the data as sufficiently reliable for engagement
purposes when you conclude the following: Both the review of
related information and the initial testing provide assurance that
(<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) the likelihood of significant errors or incompleteness is
minimal and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) the use of the data would not lead to an incorrect
or unintentional message. You could have some problems or
uncertainties about the data, but they would be minor, given the
research question and intended use of the data. When the
preliminary assessment indicates that the data are sufficiently
<ENAMEX TYPE="PERSON">reliable</ENAMEX>, use the data.
When to <ENAMEX TYPE="ORGANIZATION">Assess Data</ENAMEX> as Not <ENAMEX TYPE="WORK_OF_ART">Sufficiently Reliable for Engagement</ENAMEX>
Purposes
You can assess the data as not sufficiently reliable for
engagement purposes when you conclude the following: The review of
related information or initial testing indicates that (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>)
significant errors or incompleteness exist in some or all of the
key data elements and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) using the data would probably lead to an
incorrect or unintentional message.
When the preliminary assessment indicates that the data are not
sufficiently reliable, you should seek evidence from other sources,
including (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) alternative computerized data-the reliability of
which you should also assess-or (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) original data in the form of
surveys, case studies, or <ENAMEX TYPE="PER_DESC">expert</ENAMEX> interviews.
When to <ENAMEX TYPE="ORGANIZATION">Assess Data</ENAMEX> as of <ENAMEX TYPE="PERSON">Undetermined Reliability</ENAMEX> and Consider
Additional Work
You should coordinate with the requester if seeking evidence
from other <ENAMEX TYPE="PER_DESC">sources</ENAMEX> does not result in a source of sufficiently
reliable data. Inform the requester that such data, needed to
respond to the request, are unavailable. Reach an agreement with
the requester to


•
redefine the research questions to eliminate the need to
use the data,


•
end the engagement, or


•
use the data with appropriate disclaimers.


Remember that you-not the requester-are responsible for deciding
what data to use. If you decide you must use data that you have
determined are not sufficiently reliable for the purposes of the
<ENAMEX TYPE="PERSON">engagement</ENAMEX>, make the limitations of the data clear, so that
incorrect or unintentional conclusions will not be drawn. Finally,
given that the data you assessed have serious reliability
weaknesses, you should include this finding in the report and
recommend that the <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> take corrective action.
You can assess the data as of undetermined reliability when you
conclude one of the following:


•
The review of some of the related information or initial
testing raises questions about the data's reliability.


•
The related information or initial testing provides too
little information to judge reliability.


•
The time or resource constraints limit the extent of the
examination of related information or initial testing.


When the preliminary assessment indicates that the reliability
of the data is undetermined, consider doing additional work to
determine reliability. <ENAMEX TYPE="LAW">Section 8</ENAMEX> provides guidance on the types of
additional work to consider, as well as suggestions if no
additional work is feasible.


<ENAMEX TYPE="LANGUAGE">Section 8</ENAMEX>: <ENAMEX TYPE="ORGANIZATION">Conducting Additional Work</ENAMEX>
When you have determined (through the preliminary assessment)
that the data are of undetermined reliability, consider conducting
additional work (see figure <NUMEX TYPE="CARDINAL">6</NUMEX>). A range of additional steps to
further determine data reliability includes tracing to and from
source documents, using advanced electronic testing, and reviewing
selected system controls. The mix depends on what weaknesses you
identified in the preliminary assessment and the circumstances
specific to your engagement, such as risk level and corroborating
evidence, as well as other factors. Focus particularly on those
aspects of the data that pose the greatest potential risk for your
engagement. You should get help from appropriate technical
<ENAMEX TYPE="PER_DESC">specialists</ENAMEX> to discuss whether additional work is required and to
carry out any part of the additional reliability assessment.
Figure <NUMEX TYPE="CARDINAL">6</NUMEX>: <ENAMEX TYPE="WORK_OF_ART">Choosing and Conducting Additional Work</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
Tracing to and from <ENAMEX TYPE="ORGANIZATION">Source Documents</ENAMEX>
Tracing a sample of data records to source documents helps you
to determine whether the computer data accurately and completely
reflect these documents. In deciding what and how to trace,
consider the relative risks to the engagement of overstating or
understating the conclusions drawn from the data, for example: On
the one hand, if you are particularly concerned that questionable
cases might not have been entered into the computer system and that
as a result, the degree of compliance may be overstated, you should
consider tracing from <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents to the database. On the
other hand, if you are more concerned that ineligible cases have
been included in the database and that as a result, the potential
problems may be understated, you should consider tracing from the
database back to source documents.
The reason to trace only a sample is because sampling saves time
and cost. To be useful, however, the sample should be random and
large enough to estimate the error rate within reasonable levels of
<ENAMEX TYPE="ORGANIZATION">precision</ENAMEX>. Tracing a random sample will provide the error rate and
the magnitude of errors for the entire data file. It is this error
rate that helps you to determine the data reliability. Generally,
every data file will have some degree of error (see example <TIMEX TYPE="DATE">1</TIMEX> for
error rate and example <TIMEX TYPE="DATE">2</TIMEX> for magnitude of errors). Consult
<ENAMEX TYPE="PER_DESC">statisticians</ENAMEX> to assist you in selecting the sampling method most
suited to the engagement.
Example <TIMEX TYPE="DATE">1</TIMEX>: According to a random sample, <NUMEX TYPE="PERCENT">10 percent</NUMEX> of the data
<ENAMEX TYPE="ORGANIZATION">records</ENAMEX> have incorrect dates. However, the dates may be off by an
average of <TIMEX TYPE="DATE">only 3 days</TIMEX>. Depending on what the data are used for, <NUMEX TYPE="CARDINAL">3</NUMEX>
<TIMEX TYPE="DATE">days</TIMEX> may not compromise reliability.
Example <TIMEX TYPE="DATE">2</TIMEX>: The value of a data element was incorrectly entered
as <NUMEX TYPE="MONEY">$100,000</NUMEX>, rather than <NUMEX TYPE="MONEY">$1,000,000</NUMEX>. The documentation of the
database shows that the acceptable range for this data element is
between <NUMEX TYPE="MONEY">$100 and $5,000,000</NUMEX>. Therefore, the electronic testing done
in the initial testing phase would have confirmed that the value of
<NUMEX TYPE="MONEY">$100,000</NUMEX> fell within that range. In this case, the error could be
caught, not by electronic testing, but only by tracing the data to
source documents.
Tracing to <ENAMEX TYPE="ORGANIZATION">Source Documents</ENAMEX>
Consider tracing to source documents when (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) the source
documents are available relatively easily or (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) the possible
magnitude of errors is especially critical.
To trace a sample to source documents, match the entered data
with the corresponding data in the source documents. But in
attempting to trace entered data back to source documents, several
problems can arise: <ENAMEX TYPE="ORGANIZATION">Source</ENAMEX> documents may not be available because
they were destroyed, were never created, or are not centrally
located.
Several options exist if <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents are not available. For
those documents never created-for example, when data may be based
on electronic submissions-use interviews to obtain related
information, any corroborating evidence obtained <TIMEX TYPE="DATE">earlier</TIMEX>, or a
review of the adequacy of <ENAMEX TYPE="ORG_DESC">system</ENAMEX> controls.
Tracing from <ENAMEX TYPE="ORGANIZATION">Source Documents</ENAMEX>
Consider tracing from <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents, instead of or in
addition to tracing a sample to source documents, when you have
concerns that the data are not complete. To trace a sample from
source documents, match the source documents with the entered data.
Such tracing may be appropriate to determine whether all data are
completely entered. However, if <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents were never created
or are now missing, you cannot identify the missing data.
Using <ENAMEX TYPE="ORGANIZATION">Advanced Electronic Testing</ENAMEX>
Advanced electronic testing goes beyond the basic electronic
testing that you did in initial testing (see <ENAMEX TYPE="LAW">section 5</ENAMEX>). It
generally requires specialized computer programs to test for
specific conditions in the data. Such testing can be particularly
helpful in determining the accuracy and completeness of processing
by the application system that produced the data. Consider using
advanced electronic testing for
<ENAMEX TYPE="PERSON">•</ENAMEX> following up on troubling aspects of the data-such as
extremely high values associated with a certain geographic
location-found in initial testing or while analyzing the data;
Reviewing <ENAMEX TYPE="ORGANIZATION">Selected System Controls</ENAMEX>


•
testing relationships-cross-<NUMEX TYPE="CARDINAL">tabulation</NUMEX>-between data
<ENAMEX TYPE="PER_DESC">elements</ENAMEX>, such as whether data elements follow a skip pattern from
a questionnaire; and


•
verifying that computer processing is accurate and
complete, such as testing a formula used in generating specific
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> elements.


Depending on what will be tested, this testing can require a
range of programming skills-from creating cross-tabulations on
related data elements to duplicating an intricate automated process
with more advanced programming techniques. Consult appropriate
technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX>, as needed.
Your review of selected <ENAMEX TYPE="ORG_DESC">system</ENAMEX> controls-the underlying
structures and processes of the computer in which the data are
maintained-can provide some assurance that the data are
sufficiently reliable. Examples of <ENAMEX TYPE="ORG_DESC">system</ENAMEX> controls are limits on
access to the system and edit checks on data entered into the
system. Controls can reduce, to an acceptable level, the risk that
a significant mistake could occur and remain undetected and
<ENAMEX TYPE="ORGANIZATION">uncorrected</ENAMEX>. Limit the review to evaluating the specific controls
that can most directly affect the reliability of the data in
question. Choose areas for review on the basis of what is known
about the system. Sometimes, you identify potential <ENAMEX TYPE="ORG_DESC">system</ENAMEX> control
problems in the initial steps of the assessment. Other times, you
learn during the preliminary assessment that <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents are
not readily available. Therefore, a review of selected system
controls is the best method to determine if data were entered
reliably. If needed, consult information system <ENAMEX TYPE="PER_DESC">auditors</ENAMEX> for help
in evaluating general and application controls.
Using what you know about the system, concentrate on evaluating
the controls that most directly affect the data. These controls
will usually include (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) certain general controls, such as logical
access and control of changes to the data, and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) the application
controls that help to ensure that the data are accurate and
complete, as well as authorized.
The steps for reviewing selected <ENAMEX TYPE="ORG_DESC">system</ENAMEX> controls are


•
gain a detailed understanding of the system as it relates
to the data and


•
identify and assess the application and general controls
that are critical to ensuring the reliability of the data required
for the engagement.


In some situations, it may not be feasible to perform any
additional work,
Using <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> of

for example, when (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) given a short
<ENAMEX TYPE="ORGANIZATION">time</ENAMEX> frame (too short for a complete assessment), (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) original
<ENAMEX TYPE="ORGANIZATION">computer</ENAMEX> files have been deleted, or (<ENAMEX TYPE="CONTACT_INFO">3</ENAMEX>) access to Reliability
needed documents is unavailable. See <ENAMEX TYPE="LAW">section 9</ENAMEX> for how to
proceed.


<ENAMEX TYPE="LANGUAGE">Section 9</ENAMEX>: <ENAMEX TYPE="WORK_OF_ART">Making the Final Assessment</ENAMEX>
During the final assessment, you should consider the results of
all your previous work to determine whether, for your intended use,
the data are sufficiently reliable, not sufficiently reliable, or
still undetermined. Again, remember that you are not attesting to
the reliability of the data or database. You are only determining
the sufficiency of the reliability of the data for your intended
use. The final assessment will help you decide what actions to take
(see figure <NUMEX TYPE="CARDINAL">7</NUMEX>).
Figure <NUMEX TYPE="CARDINAL">7</NUMEX>: <ENAMEX TYPE="WORK_OF_ART">Making the Final Assessment</ENAMEX>

Source: <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>.
The following are some considerations to help you decide whether
you can use the data:


•
The corroborating evidence is strong.


•
The degree of risk is low.


•
The results of additional assessment (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) answered issues
raised in the preliminary assessment and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) did not raise any new
questions.


•
The error rate, in tracing to or from <ENAMEX TYPE="PER_DESC">source</ENAMEX> documents,
did not compromise reliability.


In making this assessment, you should consult with appropriate
technical <ENAMEX TYPE="PER_DESC">specialists</ENAMEX>.
You can consider the data sufficiently reliable when you
conclude the following: On the basis of the additional work, as
well as the initial assessment work, using the data would not
weaken the analysis nor lead to an incorrect or unintentional
message. You could have some problems or uncertainties about the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>, but they would be minor, given the research question and
intended use of the data. When your final assessment indicates that
the data are reliable, use the data.
<ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data</ENAMEX>
Not <ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data</ENAMEX>
You can consider the data to be not sufficiently reliable when
you conclude the following: On the basis of information drawn from
the additional assessment, as well as the preliminary assessment,
(<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) using the data would most likely lead to an incorrect or
unintentional message and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) the data have significant or
potentially significant limitations, given the research question
and intended use of the data.
When you determine that the data are not sufficiently reliable,
you should inform the requester that sufficiently reliable data,
needed to respond to the request, are unavailable. Remember that
you-not the requester-are responsible for deciding what data to
use. Although the requester may want information based on
insufficiently reliable data, you are responsible for ensuring that
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> are used appropriately to respond to the requester. If you
decide to use the data for the report, make the limitations of the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> clear, so that incorrect or unintentional conclusions will not
be arrived at. Appropriate <ENAMEX TYPE="ORG_DESC">team</ENAMEX> <ENAMEX TYPE="PER_DESC">management</ENAMEX> should be consulted
before you agree to use data that are not sufficiently
reliable.
Finally, given that the data you assessed have serious
reliability weaknesses, you should include this finding in the
<ENAMEX TYPE="ORGANIZATION">report</ENAMEX> and recommend that the <ENAMEX TYPE="ORG_DESC">agency</ENAMEX> take corrective action.
<ENAMEX TYPE="ORGANIZATION">Data of Undetermined</ENAMEX> Reliability
You can consider the data to be of undetermined reliability when
you conclude the following: On the basis of the information drawn
from any additional work, as well as the preliminary assessment,
(<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) use of the data could lead to a incorrect or unintentional
message and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) the data have significant or potentially
significant limitations, given the research question and the
intended use. You can consider the data to be of undetermined
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX> if specific factors-such as short time frames, the
deletion of original computer files, and the lack of access to
needed documents-are present. If you decide to use the data, make
the limitations of the data clear, so that incorrect or
unintentional conclusions will not be arrived at.
As noted above in the case of not sufficiently reliable data,
when you determine that the data are of undetermined reliability,
you should inform the requester-if appropriate-that sufficiently
reliable data, needed to respond to the request, are unavailable.
Remember that you-not the requester-are responsible for deciding
what data to use. Although the requester may want information based
on data of undetermined reliability, you are responsible for
ensuring that appropriate data are used to respond to the
<ENAMEX TYPE="ORGANIZATION">requester</ENAMEX>. If you decide to use the data in your report, make the
limitations clear, so that incorrect or unintentional conclusions
will not be arrived at. Appropriate <ENAMEX TYPE="ORG_DESC">team</ENAMEX> <ENAMEX TYPE="PER_DESC">management</ENAMEX> should be
consulted before you agree to use data of undetermined
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX>.


<ENAMEX TYPE="LAW">Section 10</ENAMEX>: <ENAMEX TYPE="WORK_OF_ART">Including Appropriate Language in the Report</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Sufficiently Reliable Data</ENAMEX>
In the report, you should include a statement in the methodology
<ENAMEX TYPE="LANGUAGE">section</ENAMEX> about conformance to generally accepted government auditing
standards (GAGAS). These standards refer to how you did your work,
not how reliable the data are. Therefore, you are conforming to
<ENAMEX TYPE="ORGANIZATION">GAGAS</ENAMEX> as long as, in reporting, you discuss what you did to assess
the data; disclose any data concerns; and reach a judgment about
the reliability of the data for use in the report.
Furthermore, in the methodology section, include a discussion of
your assessment of data reliability and the basis for this
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>. The language in this discussion will vary, depending on
whether the data are sufficiently reliable, not sufficiently
<ENAMEX TYPE="PERSON">reliable</ENAMEX>, or of undetermined reliability. In addition, you may need
to discuss the reliability of the data in other sections of the
report. Whether you do so depends on the importance of the data to
the message.
Present your basis for assessing the data as sufficiently
<ENAMEX TYPE="PERSON">reliable</ENAMEX>, given the research questions and intended use of the
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX>. This presentation includes (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) noting what kind of assessment
you relied on, (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) explaining the steps in the assessment, and (<ENAMEX TYPE="CONTACT_INFO">3</ENAMEX>)
disclosing any data limitations. Such disclosure includes


•
telling why using the data would not lead to an incorrect
or unintentional message,


•
explaining how limitations could affect any expansion of
the message, and


•
pointing out that any data limitations are minor in the
context of the engagement.


Present your basis for assessing the data as not sufficiently
<ENAMEX TYPE="PERSON">reliable</ENAMEX>, given
Not Sufficiently

the research questions and intended
use of the data. This presentation should include what kind of
assessment you relied on, with an explanation of the steps in the
<ENAMEX TYPE="ORGANIZATION">assessment</ENAMEX>.
<ENAMEX TYPE="ORGANIZATION">Data of Undetermined</ENAMEX> Reliability
In this explanation, (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>) describe the problems with the data, as
well as why using the data would probably lead to an incorrect or
unintentional message, and (<ENAMEX TYPE="CONTACT_INFO">2</ENAMEX>) <ENAMEX TYPE="GPE_DESC">state</ENAMEX> that the data problems are
significant or potentially significant. In addition, if the report
contains a conclusion or recommendation supported by evidence other
than these data, state that fact. Finally, if the data you assessed
are not sufficiently reliable, you should include this finding in
the report and recommend that the audited <ENAMEX TYPE="ORG_DESC">entity</ENAMEX> take corrective
action.
Present your basis for assessing the reliability of the data as
undetermined. Include such factors as short time frames, the
deletion of original computer files, and the lack of access to
needed documents. Explain the reasonableness of using the data, for
example: These are the only available data on the subject; the data
are widely used by outside <ENAMEX TYPE="PER_DESC">experts</ENAMEX> or policymakers; or the data are
supported by credible corroborating evidence. In addition, make the
limitations of the data clear, so that incorrect or unintentional
conclusions will not be drawn from the data. For example, indicate
how the use of these data could lead to an incorrect or
unintentional message. Finally, if the report contains a conclusion
or recommendation supported by evidence other than these data,
state that fact.


Glossary of <ENAMEX TYPE="ORGANIZATION">Technical Terms</ENAMEX>
accuracy. Freedom from error in the data.
<ENAMEX TYPE="PERSON">completeness</ENAMEX>. The inclusion of all necessary parts or
<ENAMEX TYPE="PER_DESC">elements</ENAMEX>.
database. A collection of related data files (for example,
questionnaire responses from several different <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> of <ENAMEX TYPE="PER_DESC">people</ENAMEX>,
with each <ENAMEX TYPE="ORG_DESC">group</ENAMEX>'s identity maintained.)
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> element. An <ENAMEX TYPE="PER_DESC">individual</ENAMEX> piece of information that has
definable parameters, sometimes referred to as variables or fields
(for example, the response to any question in a questionnaire).
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> file. A collection of related data records, also referred
to as a data set (for example, the collected questionnaire
responses from a group of <ENAMEX TYPE="PER_DESC">people</ENAMEX>).
<ENAMEX TYPE="ORGANIZATION">data</ENAMEX> record. A collection of related data elements that relate
to a specific event, transaction, or occurrence (for example,
questionnaire responses <NUMEX TYPE="CARDINAL">about one</NUMEX> <ENAMEX TYPE="PER_DESC">individual</ENAMEX>-such as age, sex, and
marital status).
source document. Information that is the basis for entry of data
into a computer.
<ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s <ENAMEX TYPE="GPE">Mission</ENAMEX>
The <ENAMEX TYPE="ORGANIZATION">General Accounting Office</ENAMEX>, the investigative <ENAMEX TYPE="ORG_DESC">arm</ENAMEX> of
<ENAMEX TYPE="ORGANIZATION">Congress</ENAMEX>, exists to support <ENAMEX TYPE="ORGANIZATION">Congress</ENAMEX> in meeting its constitutional
responsibilities and to help improve the performance and
accountability of the federal <ENAMEX TYPE="ORG_DESC">government</ENAMEX> for the <ENAMEX TYPE="NATIONALITY">American</ENAMEX> <ENAMEX TYPE="PER_DESC">people</ENAMEX>.
<ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> examines the use of public funds; evaluates federal programs
and policies; and provides analyses, recommendations, and other
assistance to help <ENAMEX TYPE="ORGANIZATION">Congress</ENAMEX> make informed oversight, policy, and
funding decisions. <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s commitment to good <ENAMEX TYPE="ORG_DESC">government</ENAMEX> is reflected
in its core values of accountability, integrity, and
<ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX>.
<ENAMEX TYPE="PERSON">Obtaining Copies</ENAMEX> of <ENAMEX TYPE="ORGANIZATION">GAO Reports</ENAMEX> and Testimony
The fastest and easiest way to obtain copies of <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> documents at
no cost is through the Internet. <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>'s Web site (<ENAMEX TYPE="CONTACT_INFO">www.</ENAMEX><ENAMEX TYPE="PERSON">gao</ENAMEX>.<ENAMEX TYPE="CONTACT_INFO">gov</ENAMEX>)
contains abstracts and fulltext files of current reports and
testimony and an expanding archive of older products. The Web site
features a search engine to help you locate documents using key
words and phrases. You can print these documents in their entirety,
including charts and other graphics.
<TIMEX TYPE="DATE">Each day</TIMEX>, <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> issues a list of newly released reports,
testimony, and correspondence. <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> posts this list, known as
"<ENAMEX TYPE="WORK_OF_ART">Today's Reports</ENAMEX>," on its Web site <TIMEX TYPE="DATE">daily</TIMEX>. The list contains links
to the full-text document files. To have <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> e-mail this list to
you every <TIMEX TYPE="TIME">afternoon</TIMEX>, go to <ENAMEX TYPE="CONTACT_INFO">www.</ENAMEX><ENAMEX TYPE="PERSON">gao</ENAMEX>.<ENAMEX TYPE="CONTACT_INFO">gov</ENAMEX> and select "<ENAMEX TYPE="WORK_OF_ART">Subscribe to</ENAMEX>
daily E-mail alert for newly released products" under the <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX>
Reports heading.
Order by <ENAMEX TYPE="ORGANIZATION">Mail</ENAMEX> or Phone
The <NUMEX TYPE="ORDINAL">first</NUMEX> copy of each printed report is free. Additional copies
are <NUMEX TYPE="MONEY">$2</NUMEX> each. A check or money order should be made out to the
<ENAMEX TYPE="PER_DESC">Superintendent</ENAMEX> of Documents. <ENAMEX TYPE="ORGANIZATION">GAO</ENAMEX> also accepts <ENAMEX TYPE="ORGANIZATION">VISA</ENAMEX> and <ENAMEX TYPE="ORGANIZATION">Mastercard</ENAMEX>.
Orders for <NUMEX TYPE="CARDINAL">100</NUMEX> or more copies mailed to a single address are
discounted <NUMEX TYPE="PERCENT">25 percent</NUMEX>. Orders should be sent to:
<ENAMEX TYPE="ORGANIZATION">U.S. General Accounting Office</ENAMEX> <NUMEX TYPE="CARDINAL">441</NUMEX> <ENAMEX TYPE="FAC">G Street</ENAMEX> NW, Room LM
<ENAMEX TYPE="GPE">Washington</ENAMEX>, <ENAMEX TYPE="GPE">D.C.</ENAMEX> 20548
To order by Phone: <ENAMEX TYPE="ORGANIZATION">Voice</ENAMEX>: (<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <TIMEX TYPE="DATE">512-6000</TIMEX> TDD: (<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <ENAMEX TYPE="CONTACT_INFO">512-2537</ENAMEX>
Fax: (<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <ENAMEX TYPE="CONTACT_INFO">512-6061</ENAMEX>
Contact:
To Report <ENAMEX TYPE="GPE">Fraud</ENAMEX>, Web site: <ENAMEX TYPE="CONTACT_INFO">www.</ENAMEX><ENAMEX TYPE="PERSON">gao</ENAMEX>.<ENAMEX TYPE="CONTACT_INFO">gov/fraudnet/fraudnet.</ENAMEX><ENAMEX TYPE="CONTACT_INFO">htm</ENAMEX>

E-mail: fraudnet@<TIMEX TYPE="DATE">gao</TIMEX>.<ENAMEX TYPE="CONTACT_INFO">gov</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Federal Programs Automated</ENAMEX> answering system: (<ENAMEX TYPE="CONTACT_INFO">800</ENAMEX>) <ENAMEX TYPE="CONTACT_INFO">424-5454</ENAMEX> or
(<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>) <ENAMEX TYPE="CONTACT_INFO">512-7470</ENAMEX>
<ENAMEX TYPE="PERSON">Jeff Nelligan</ENAMEX>, <ENAMEX TYPE="PER_DESC">managing director</ENAMEX>, <ENAMEX TYPE="ORGANIZATION">NelliganJ</ENAMEX>@<TIMEX TYPE="DATE">gao</TIMEX>.<ENAMEX TYPE="CONTACT_INFO">gov</ENAMEX> (<ENAMEX TYPE="CONTACT_INFO">202</ENAMEX>)
<ENAMEX TYPE="CONTACT_INFO">512-4800</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">Public Affairs</ENAMEX>
<ENAMEX TYPE="ORGANIZATION">U.S. GeneralAccounting Office</ENAMEX>, <NUMEX TYPE="CARDINAL">441</NUMEX> <ENAMEX TYPE="FAC">G Street</ENAMEX> NW, Room <TIMEX TYPE="DATE">7149</TIMEX>
<ENAMEX TYPE="GPE">Washington</ENAMEX>, <ENAMEX TYPE="GPE">D.C.</ENAMEX> 20548

<ENAMEX TYPE="ORGANIZATION">Presorted Standard Postage & Fees Paid GAO Permit No.</ENAMEX>
GI00
<ENAMEX TYPE="ORGANIZATION">United States General Accounting Office Washington</ENAMEX>, <ENAMEX TYPE="GPE">D.C.</ENAMEX>
<ENAMEX TYPE="CONTACT_INFO">20548-0001</ENAMEX>
Official <ENAMEX TYPE="ORGANIZATION">Business Penalty</ENAMEX> for Private Use <NUMEX TYPE="MONEY">$300</NUMEX>
<ENAMEX TYPE="ORGANIZATION">Address Service Requested</ENAMEX>




