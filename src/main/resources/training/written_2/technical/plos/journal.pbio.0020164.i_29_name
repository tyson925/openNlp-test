
  
    
      
        
        Why is the sky blue? Any <ENAMEX TYPE="PER_DESC">scientist</ENAMEX> will answer this question with a statement of
        mechanism: Atmospheric gas scatters some wavelengths of light more than others. To answer
        with a statement of purpose‚Äîe.<ENAMEX TYPE="PERSON">g.</ENAMEX>, to say the sky is blue in order to make people
        happy‚Äîwould not cross the scientific mind. Yet in biology we often pose ‚Äúwhy‚Äù questions in
        which it is purpose, not mechanism, that interests us. The question ‚ÄúWhy does the eye have
        a <ENAMEX TYPE="PRODUCT">lens?‚</ENAMEX>Äù most often calls for the answer that the <ENAMEX TYPE="PRODUCT">lens</ENAMEX> is there to focus light rays, and
        only rarely for the answer that the <ENAMEX TYPE="PRODUCT">lens</ENAMEX> is there because lens cells are induced by the
        retina from overlying ectoderm.
        It is a legacy of evolution that teleology‚Äîthe tendency to explain natural phenomena in
        terms of purposes‚Äîis deeply ingrained in biology, and not in other fields (<ENAMEX TYPE="PERSON">Ayala 1999).</ENAMEX>
        Natural selection has so molded biological <ENAMEX TYPE="ORG_DESC">entities</ENAMEX> that nearly everything <NUMEX TYPE="CARDINAL">one</NUMEX> looks at<ENAMEX TYPE="CONTACT_INFO">,</ENAMEX>
        from molecules to cells, from organ systems to ecosystems, has (at <NUMEX TYPE="CARDINAL">one</NUMEX> time at least) been
        retained because it carries out a function that enhances fitness. It is natural to equate
        such functions with purposes. Even if we can't actually know why something evolved, we care
        about the useful things it does that could account for its evolution.
        As a <ENAMEX TYPE="ORG_DESC">group</ENAMEX>, molecular <ENAMEX TYPE="PER_DESC">biologists</ENAMEX> shy away from teleological matters, perhaps because
        early attitudes in molecular biology were shaped by physicists and <ENAMEX TYPE="PER_DESC">chemists</ENAMEX>. Even
        geneticists rigorously define function not in terms of the useful things a gene does, but
        by what happens when the gene is altered. Molecular biology and molecular genetics might
        continue to dodge teleological issues were it not for their fields' remarkable recent
        successes. <ENAMEX TYPE="ORGANIZATION">Mechanistic</ENAMEX> information about how a multitude of <ENAMEX TYPE="SUBSTANCE">genes</ENAMEX> and <ENAMEX TYPE="SUBSTANCE">gene products</ENAMEX> act and
        <ENAMEX TYPE="PERSON">interact</ENAMEX> is now being gathered so rapidly that our inability to synthesize such information
        into a coherent whole is becoming more and more frustrating. Gene regulation, intracellular
        signaling pathways, metabolic <ENAMEX TYPE="ORG_DESC">networks</ENAMEX>, developmental programs‚Äîthe current information
        <ENAMEX TYPE="PERSON">deluge</ENAMEX> is revealing these systems to be so complex that molecular <ENAMEX TYPE="PER_DESC">biologists</ENAMEX> are forced to
        wrestle with an overtly teleological question: What purpose does all this complexity
        serve?
        In response to this situation, <NUMEX TYPE="CARDINAL">two</NUMEX> strains have emerged in molecular biology, both of
        which are sometimes lumped under the heading ‚Äúsystems biology.‚Äù One strain, bioinformatics,
        champions the gathering of even larger amounts of new data, both descriptive and
        mechanistic, followed by computerbased data ‚Äúmining‚Äù to identify correlations from which
        insightful hypotheses are likely to emerge. The other strain, computational biology, begins
        with the complex interactions we already know about, and uses computer-aided mathematics to
        explore the consequences of those interactions. Of course, bioinformatics and computational
        biology are not entirely separable <ENAMEX TYPE="ORG_DESC">entities</ENAMEX>; they represent ends of a spectrum, differing
        in the degree of emphasis placed on large versus small data sets, and statistical versus
        deterministic analyses.
        Computational biology, in the sense used above, arouses some skepticism among
        <ENAMEX TYPE="PER_DESC">scientists</ENAMEX>. To some, it recalls the <ENAMEX TYPE="ANIMAL">‚Äúmathematical biology‚Äù</ENAMEX> that, starting from its heyday
        in <TIMEX TYPE="DATE">the 1960s</TIMEX>, provided some interesting insights, but also succeeded in elevating the term
        <ENAMEX TYPE="PERSON">‚Äúmodeling‚Äù</ENAMEX> to near-pejorative status among many <ENAMEX TYPE="PER_DESC">biologists</ENAMEX>. For the most part, mathematical
        <ENAMEX TYPE="PERSON">biologists</ENAMEX> sought to fit biological data to relatively simple mathematical models, with the
        hope that fundamental laws might be recognized (<ENAMEX TYPE="PERSON">Fox Keller 2002).</ENAMEX> This strategy works well
        in physics and chemistry, but in biology it is stymied by <NUMEX TYPE="CARDINAL">two</NUMEX> problems. First, biological
        <ENAMEX TYPE="ORGANIZATION">data</ENAMEX> are usually incomplete and extremely imprecise. As new measurements are made, <TIMEX TYPE="DATE">today</TIMEX>'s
        models rapidly join <TIMEX TYPE="DATE">tomorrow</TIMEX>'s trash heaps. <NUMEX TYPE="ORDINAL">Second</NUMEX>, because biological phenomena are
        generated by large, complex networks of elements, there is little reason to expect to
        discern fundamental laws in them. To do so would be like expecting to discern the
        fundamental laws of electromagnetism in the output of a personal computer.
        <ENAMEX TYPE="PERSON">Nowadays</ENAMEX>, many <ENAMEX TYPE="PER_DESC">computational biologists</ENAMEX> avoid modeling-<NUMEX TYPE="CARDINAL">as</NUMEX>-data-fitting, opting instead
        to create <ENAMEX TYPE="PRODUCT_DESC">models</ENAMEX> in which <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> are specified in terms of elements and interactions (the
        network <ENAMEX TYPE="CONTACT_INFO">‚Äútopology‚Äù</ENAMEX>), but the numerical values that quantify those interactions (the
        parameters) are deliberately varied over wide ranges. As a result, the study of such
        <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> focuses not on the exact values of outputs, but rather on qualitative behavior,
        e.g., whether the <ENAMEX TYPE="ORG_DESC">network</ENAMEX> acts as a <ENAMEX TYPE="CONTACT_INFO">‚Äúswitch,‚Äù ‚Äúfilter,‚Äù ‚Äúoscillator,‚Äù ‚</ENAMEX>Äúdynamic range
        <ENAMEX TYPE="CONTACT_INFO">adjuster,‚Äù ‚</ENAMEX>Äúproducer of stripes,‚Äù etc. By investigating how such behaviors change for
        different parameter sets‚Äî an exercise referred to <NUMEX TYPE="MONEY">as ‚</NUMEX>Äúexploring the parameter space‚Äù‚Äîone
        starts to assemble a comprehensive picture of all the kinds of behaviors a <ENAMEX TYPE="ORG_DESC">network</ENAMEX> can
        produce. If <NUMEX TYPE="CARDINAL">one</NUMEX> such behavior seems useful (to the <ENAMEX TYPE="SUBSTANCE">organism</ENAMEX>), it becomes a candidate for
        explaining why the <ENAMEX TYPE="ORG_DESC">network</ENAMEX> itself was selected, i.e., it is seen as a potential purpose for
        the <ENAMEX TYPE="ORG_DESC">network</ENAMEX>. If experiments subsequently support assignments of actual parameter values to
        the range of parameter space that produces such behavior, then the potential purpose
        becomes a likely one.
        For very simple <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> (e.g., linear pathways with no delays or feedback and with
        constant inputs), possible global behaviors are usually limited, and computation rarely
        reveals <NUMEX TYPE="CARDINAL">more than one</NUMEX> could have gleaned through intuition alone. In contrast, when
        <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> become even slightly complex, intuition often fails, sometimes spectacularly so,
        and computation becomes essential.
        For example, intuitive thinking about MAP kinase pathways led to the long-held view that
        the obligatory cascade of <NUMEX TYPE="CARDINAL">three</NUMEX> sequential <ENAMEX TYPE="ORG_DESC">kinases</ENAMEX> serves to provide signal amplification.
        In contrast, computational studies have suggested that the purpose of such a network is to
        achieve extreme positive cooperativity, so that the pathway behaves in a switch-like,
        rather than a graded, fashion (<ENAMEX TYPE="PERSON">Huang</ENAMEX> and <ENAMEX TYPE="PERSON">Ferrell 1996).</ENAMEX> Another example comes from the
        study of <ENAMEX TYPE="DISEASE">morphogen gradient</ENAMEX> formation in animal development. Whereas intuitive
        interpretations of experiments led to the conclusion that simple diffusion is not adequate
        to transport most morphogens, computational analysis of the same experimental data yields
        the opposite conclusion (<ENAMEX TYPE="ORGANIZATION">Lander et</ENAMEX> al. <TIMEX TYPE="DATE">2002</TIMEX>).
        As the power of computation to identify possible functions of complex biological
        <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> is increasingly recognized, purely (or largely) computational studies are becoming
        more common in biological <ENAMEX TYPE="ORG_DESC">journals</ENAMEX>. This raises an interesting question for the biology
        <ENAMEX TYPE="ORGANIZATION">community</ENAMEX>: In a field in which scientific contributions have long been judged in terms of
        the amount of new experimental data they contain, how does one <ENAMEX TYPE="PER_DESC">judge</ENAMEX> work that is primarily
        focused on interpreting (albeit with great effort and sophistication) the experimental data
        of others? At the simplest level, this question poses a conundrum for journal <ENAMEX TYPE="PER_DESC">editors</ENAMEX>. At a
        deeper level, it calls attention to the biology <ENAMEX TYPE="GPE_DESC">community</ENAMEX>'s difficulty in defining what,
        exactly, <ENAMEX TYPE="ANIMAL">constitutes ‚Äúinsight‚Äù</ENAMEX> (<ENAMEX TYPE="PERSON">Fox Keller 2002).</ENAMEX>
        In <TIMEX TYPE="DATE">yesterday</TIMEX>'s mathematical biology, a model's <ENAMEX TYPE="ORG_DESC">utility</ENAMEX> could always be equated with its
        ability to generate testable predictions about new experimental outcomes. This approach
        works fine when one's ambition is to build models that faithfully mimic particular
        biological phenomena. But when the goal is to identify all possible classes of biological
        phenomena that could arise from a given network topology, the connection to experimental
        <ENAMEX TYPE="PERSON">verification</ENAMEX> becomes blurred. This does not mean that computational studies of biological
        <ENAMEX TYPE="ORG_DESC">networks</ENAMEX> are disconnected from experimental reality, but rather that they tend, nowadays,
        to address questions of a higher level than simply whether a particular model fits
        particular data.
        The problem this creates for those of us who read computational biology <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> is
        knowing how to judge when a study has made a contribution that is deep, comprehensive, or
        enduring enough to be worth our attention. We can observe the field trying to sort out this
        issue in the recent literature. A good example can be found in an article by <ENAMEX TYPE="PERSON">Nicholas</ENAMEX>
        <ENAMEX TYPE="ORGANIZATION">Ingolia</ENAMEX> in this issue of 
        <ENAMEX TYPE="PERSON">PLoS Biology</ENAMEX> (<ENAMEX TYPE="PRODUCT">Ingolia 2004</ENAMEX>), and an earlier study from <ENAMEX TYPE="PERSON">Garrett Odell</ENAMEX>'s
        <ENAMEX TYPE="ORGANIZATION">group</ENAMEX>, upon which <ENAMEX TYPE="ORGANIZATION">Ingolia</ENAMEX> draws heavily (<ENAMEX TYPE="PERSON">von Dassow et al. 2000).</ENAMEX>
        Both articles deal with a classical problem in developmental biology, namely, how
        repeating patterns (such as stripes and <ENAMEX TYPE="ORG_DESC">segments</ENAMEX>) are laid down. In the early fruit fly
        embryo, it is known that a network involving cell-to-cell signaling via the <ENAMEX TYPE="ORGANIZATION">Wingless</ENAMEX> (<ENAMEX TYPE="ORGANIZATION">Wg</ENAMEX>)
        and <ENAMEX TYPE="PERSON">Hedgehog</ENAMEX> (<ENAMEX TYPE="ORGANIZATION">Hh</ENAMEX>) pathways specifies the formation and maintenance of alternating stripes
        of gene expression and cell identity. This <ENAMEX TYPE="ORG_DESC">network</ENAMEX> is clearly complex, in that <ENAMEX TYPE="ORGANIZATION">Wg</ENAMEX> and Hh
        signals affect not only downstream <ENAMEX TYPE="SUBSTANCE">genes</ENAMEX>, but also the expression and/or activity of the
        components of each other's signaling machinery.
        <ENAMEX TYPE="ORGANIZATION">Von Dassow et al.</ENAMEX> (<TIMEX TYPE="DATE">2000</TIMEX>) calculated the behaviors of various embodiments of this network
        over a wide range of parameter values and starting conditions. This was done by expressing
        the <ENAMEX TYPE="ORG_DESC">network</ENAMEX> in terms of coupled differential equations, picking parameters at random from
        within prespecified ranges, solving the equation set numerically, then picking another
        <ENAMEX TYPE="ORGANIZATION">random</ENAMEX> set of parameters and obtaining a new numerical solution, and so forth, until
        <NUMEX TYPE="CARDINAL">240,000</NUMEX> cases were tried. The solutions were then sorted into <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> based on the predicted
        output‚Äîin this case, spatial patterns of gene expression.
        When they used a network topology based only upon molecular and generegulatory
        interactions that were firmly known to take place in the embryo, they were unable to
        produce the necessary output (stable stripes), but upon inclusion of <NUMEX TYPE="CARDINAL">two</NUMEX> molecular events
        that were strongly suspected of taking place in the embryo, they produced the desired
        pattern easily. In fact, they produced it much more easily than expected. It appeared that
        a remarkably large fraction of random parameter values produced the very same stable
        stripes. This implied that the output of the <ENAMEX TYPE="ORG_DESC">network</ENAMEX> is extraordinarily robust, where
        <ENAMEX TYPE="ORGANIZATION">robustness</ENAMEX> is meant in the engineering sense of the word, namely, a relative insensitivity
        of output to variations in parameter values.
        Because real <ENAMEX TYPE="ANIMAL">organisms</ENAMEX> face changing parameter values constantly‚Äîwhether as a result of
        unstable environmental conditions, or mutations leading to the inactivation of a single
        allele of a gene‚Äîrobustness is an extremely valuable feature of biological <ENAMEX TYPE="ORG_DESC">networks</ENAMEX>, so
        much so that some have elevated it to a sort of sine qua non (<ENAMEX TYPE="ORGANIZATION">Morohashi et</ENAMEX> al. <TIMEX TYPE="DATE">2002</TIMEX>).
        Indeed, the major message of the <ENAMEX TYPE="PERSON">von Dassow</ENAMEX> article was that the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> had uncovered a
        ‚Äúrobust developmental module,‚Äù which could ensure the formation of an appropriate pattern
        even across distantly related insect <ENAMEX TYPE="ANIMAL">species</ENAMEX> whose earliest steps of embryogenesis are
        quite different from one another (<ENAMEX TYPE="PERSON">von Dassow et al. 2000).</ENAMEX>
        There is little doubt that <ENAMEX TYPE="PERSON">von Dassow</ENAMEX>'s computational study extracted an extremely
        valuable insight from what might otherwise seem like a messy and ill-specified system. But
        <ENAMEX TYPE="PERSON">Ingolia now</ENAMEX> argues that something further is needed. He proposes that it is not enough to
        show that a <ENAMEX TYPE="ORG_DESC">network</ENAMEX> performs in a certain way; one should also find out why it does so.
        Ingolia throws down the gauntlet with a simple hypothesis about why the <ENAMEX TYPE="PERSON">von Dassow</ENAMEX>
        network is so robust. He argues that it can be ascribed entirely to the ability of <NUMEX TYPE="CARDINAL">two</NUMEX>
        positive feedback loops within the system to make the network bistable. <ENAMEX TYPE="ORGANIZATION">Bistability</ENAMEX> is the
        tendency for a system's output to be drawn toward either one or the other of <NUMEX TYPE="CARDINAL">two</NUMEX> stable
        <ENAMEX TYPE="GPE_DESC">states</ENAMEX>. For example, in excitable cells such as neurons, depolarization elicits sodium
        entry, which in turn elicits depolarization‚Äîa positive feedback loop. As a result, large
        depolarizations drive neurons to fully discharge their membrane potential, whereas small
        depolarizations decay back to a resting <ENAMEX TYPE="GPE_DESC">state</ENAMEX>. Thus, the <ENAMEX TYPE="SUBSTANCE">neuron</ENAMEX> tends strongly toward one
        or the other of these <NUMEX TYPE="CARDINAL">two</NUMEX> <ENAMEX TYPE="GPE_DESC">states</ENAMEX>. The stability of each <ENAMEX TYPE="GPE_DESC">state</ENAMEX> brings with it a sort of
        intrinsic robustness‚Äî i.e., once a cell is in <NUMEX TYPE="CARDINAL">one</NUMEX> <ENAMEX TYPE="GPE_DESC">state</ENAMEX>, it takes a fairly large
        disturbance to move it into the other. This is the same principle that makes electronic
        equipment based on digital (i.e., binary) signals so much more resistant to noise than
        equipment based on analog circuitry.
        Ingolia not only argues that robustness in the <ENAMEX TYPE="PERSON">von Dassow</ENAMEX> model arises because positive
        <ENAMEX TYPE="PERSON">feedback</ENAMEX> leads to network bistability, he further claims that such <ENAMEX TYPE="ORG_DESC">network</ENAMEX> bistability is a
        consequence of bistability at the single cell level. He strongly supports these claims
        through computational explorations of parameter space that are similar to those done by <ENAMEX TYPE="PERSON">von</ENAMEX>
        <ENAMEX TYPE="ORGANIZATION">Dassow et al.</ENAMEX>, but which also use strippeddown network topologies (to focus on individual
        cell behaviors), test specifically for bistability, correlate results with the patterns
        formed, and ultimately generate a set of mathematical rules that strongly predict those
        cases that succeed or fail at producing an appropriate pattern.
        At <NUMEX TYPE="ORDINAL">first</NUMEX> glance, such a contribution might seem no more than a footnote to <ENAMEX TYPE="PERSON">von Dassow</ENAMEX>'s
        paper, but a closer look shows that this is not the case. Without mechanistic information
        <TIMEX TYPE="DATE">about</TIMEX> why the <ENAMEX TYPE="PERSON">von Dassow</ENAMEX> <ENAMEX TYPE="ORG_DESC">network</ENAMEX> does what it does, it is difficult to relate it to other
        work, or to modify it to accommodate new information or new demands. <ENAMEX TYPE="PERSON">Ingolia</ENAMEX> demonstrates
        this by deftly improving on the network topology. He inserts some new data from the
        literature about the product of an additional gene, 
        sloppy-paired , in <ENAMEX TYPE="GPE">Hh</ENAMEX> signaling, removes some of the more tenuous
        <ENAMEX TYPE="PERSON">connections</ENAMEX>, and promptly recovers a biologically essential behavior that the original <ENAMEX TYPE="PERSON">von</ENAMEX>
        Dassow network lacked: the ability to maintain a fixed pattern of gene expression even in
        the face of cell division and growth.
        Taken as a pair, the <ENAMEX TYPE="PERSON">von Dassow</ENAMEX> and <ENAMEX TYPE="ORGANIZATION">Ingolia</ENAMEX> <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> illustrate the value of complementary
        approaches in the analysis of complex biological systems. Whereas one emphasizes simulation
        (as embodied in the numerical solution of differential equations), the other emphasizes
        analysis (the mathematical analysis of the behavior of a set of equations). Whereas one
        emphasizes exploration (exploring a parameter space), the other emphasizes the testing of
        <ENAMEX TYPE="ORGANIZATION">hypotheses</ENAMEX> (about the origins of robustness). The same themes can be seen in sets of papers
        on other topics. For example, in their analysis of bacterial chemotaxis, <ENAMEX TYPE="ORGANIZATION">Leibler</ENAMEX> and
        <ENAMEX TYPE="PER_DESC">colleagues</ENAMEX> (<ENAMEX TYPE="ORGANIZATION">Barkai</ENAMEX> and <ENAMEX TYPE="PRODUCT">Leibler 1997</ENAMEX>) found a particular model to be extremely robust in the
        production of an important behavior (exact signal adaptation), and subsequently showed that
        bacteria do indeed exhibit such robust adaptation (<ENAMEX TYPE="ORGANIZATION">Alon et</ENAMEX> al. <TIMEX TYPE="DATE">1999</TIMEX>). Although <ENAMEX TYPE="ORGANIZATION">Leibler</ENAMEX> and
        <ENAMEX TYPE="PER_DESC">colleagues</ENAMEX> took significant steps toward identifying and explaining how such robustness
        came about, it took a subsequent <ENAMEX TYPE="ORG_DESC">group</ENAMEX> (<ENAMEX TYPE="ORGANIZATION">Yi et</ENAMEX> al. <TIMEX TYPE="DATE">2000</TIMEX>) to show that robustness emerged as
        a consequence of a simple engineering design principle known as ‚Äúintegral feedback
        <ENAMEX TYPE="ORGANIZATION">control</ENAMEX>.‚Äù That <ENAMEX TYPE="ORG_DESC">group</ENAMEX> also showed, through mathematical analysis, that integral feedback
        <ENAMEX TYPE="ORGANIZATION">control</ENAMEX> is the only feedback strategy capable of achieving the requisite degree of
        <ENAMEX TYPE="ORGANIZATION">robustness</ENAMEX>.
        From these and many other examples in the literature, one can begin to discern several
        of the elements that, when present together, elevate investigations in computational
        biology to a level at which ordinary <ENAMEX TYPE="PER_DESC">biologists</ENAMEX> take serious notice. Such elements include
        network topologies anchored in experimental data, fine-grained explorations of large
        <ENAMEX TYPE="ORGANIZATION">parameter</ENAMEX> spaces, identification of ‚Äúuseful‚Äù network behaviors, and hypothesisdriven
        analyses of the mathematical or statistical <ENAMEX TYPE="FAC_DESC">bases</ENAMEX> for such behaviors. These <ENAMEX TYPE="PER_DESC">elements</ENAMEX> can be
        seen as the foundations of a new calculus of purpose, enabling <ENAMEX TYPE="PER_DESC">biologists</ENAMEX> to take on the
        much-neglected teleological side of molecular biology. ‚ÄúWhat purpose does all this
        complexity serve?‚Äù may soon go from a question few <ENAMEX TYPE="PER_DESC">biologists</ENAMEX> dare to pose, to <NUMEX TYPE="CARDINAL">one</NUMEX> on
        everyone's lips.
      
    
  
