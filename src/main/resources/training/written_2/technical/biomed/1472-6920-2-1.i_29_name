
  
    
      
        Background
        Learning the skills of physical diagnosis is a critical
        part of the medical school curriculum. While there is
        widespread agreement on what skills should be learned [ <NUMEX TYPE="CARDINAL">1 2</NUMEX>
        ] , there is little information on how well those skills
        are learned, especially among second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX>.
        Measuring skill acquisition objectively is the essential
        <NUMEX TYPE="ORDINAL">first</NUMEX> step in improving clinical competence throughout
        <ENAMEX TYPE="PERSON">undergraduate</ENAMEX> and postgraduate training [ <NUMEX TYPE="CARDINAL">3 4</NUMEX> ] .
        During <TIMEX TYPE="DATE">the past 25 years</TIMEX>, the objective structured
        clinical evaluation or examination (OSCE) has become an
        important method of assessing skills at all levels of
        medical training [ <NUMEX TYPE="CARDINAL">5 6</NUMEX> ] , complementing traditional
        evaluations of knowledge that use written multiple choice
        questions and essay questions. Compared with other levels
        of training [ <ENAMEX TYPE="LAW">7</ENAMEX> ] , little is known about the use of the
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> in physical diagnosis <ENAMEX TYPE="FAC_DESC">courses</ENAMEX> for second-year medical
        <ENAMEX TYPE="PER_DESC">students</ENAMEX>.
        Several studies have used the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> to assess the effect
        of educational interventions on specific skills at the
        second-year level, such as history-taking for smoking [ <ENAMEX TYPE="LAW">8</ENAMEX> ]
        , or examination of low back pain [ <ENAMEX TYPE="LAW">9</ENAMEX> ] or the breast [ <NUMEX TYPE="CARDINAL">10</NUMEX>
        <NUMEX TYPE="CARDINAL">11</NUMEX> ] . Others have examined the use of different
        examination <ENAMEX TYPE="PER_DESC">personnel</ENAMEX> as <ENAMEX TYPE="PER_DESC">examiners</ENAMEX> or <ENAMEX TYPE="PER_DESC">patients</ENAMEX> [ <NUMEX TYPE="CARDINAL">12 13 14</NUMEX> ]
        , compared <ENAMEX TYPE="PER_DESC">students</ENAMEX>' course feedback to their OSCE
        performance [ <TIMEX TYPE="DATE">15</TIMEX> ] , examined costs [ <NUMEX TYPE="CARDINAL">12 16</NUMEX> ] or
        <ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX> and generalizability [ <ENAMEX TYPE="LAW">7</ENAMEX> ] , compared training
        locations [ <TIMEX TYPE="DATE">17</TIMEX> ] or provided general descriptions of their
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>'s [ <NUMEX TYPE="CARDINAL">18 19 20 21 22</NUMEX> ] . We found no studies that have
        used the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> to report comprehensively on the spectrum of
        skills learned in a second-year physical diagnosis course.
        A comprehensive investigation is likely to help determine
        what aspects of the educational process should be
        improved.
        We used the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> to examine how well second-year
        <ENAMEX TYPE="PER_DESC">students</ENAMEX> learned clinical skills in the second-year
        physical diagnosis course at <ENAMEX TYPE="ORGANIZATION">Harvard Medical School</ENAMEX>. We
        were particularly interested which skills students
        performed best and which were most difficult. We assessed
        what factors affected their performance on the overall
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, and on individual skills and <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>. Finally, we
        examined whether <ENAMEX TYPE="PER_DESC">student</ENAMEX> OSCE scores varied from <TIMEX TYPE="DATE">year</TIMEX> to
        <TIMEX TYPE="DATE">year</TIMEX>, medical <ENAMEX TYPE="PER_DESC">students</ENAMEX> performed differently from dental
        <ENAMEX TYPE="PER_DESC">students</ENAMEX>, learning at different teaching sites affected
        student performance, and preceptors and examination
        logistics affected student scores.
      
      
        Methods
        
          Setting
          This study took place at <ENAMEX TYPE="ORGANIZATION">Harvard Medical School</ENAMEX> as
          part of the required second-year physical diagnosis
          course, <ENAMEX TYPE="PRODUCT">Patient-Doctor II</ENAMEX> [ <ENAMEX TYPE="LAW">4</ENAMEX> ] . The <ENAMEX TYPE="FAC_DESC">course</ENAMEX> is taught
          from <TIMEX TYPE="DATE">September</TIMEX> to <TIMEX TYPE="DATE">May</TIMEX> in the same general sequence at <NUMEX TYPE="CARDINAL">9</NUMEX>
          clinical <ENAMEX TYPE="FAC_DESC">sites</ENAMEX> affiliated with the medical school. Each
          site is assigned <NUMEX TYPE="CARDINAL">6-45</NUMEX> <ENAMEX TYPE="PER_DESC">students</ENAMEX> for <TIMEX TYPE="TIME">the entire 220-hour</TIMEX>
          course, including a total of <NUMEX TYPE="CARDINAL">30</NUMEX> second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX> from
          <ENAMEX TYPE="ORGANIZATION">Harvard School of Dental Medicine</ENAMEX>. These dental students
          are preparing for careers in <ENAMEX TYPE="ANIMAL">consultative dentistry</ENAMEX> and
          are required to learn the same clinical skills as <ENAMEX TYPE="ORGANIZATION">Harvard</ENAMEX>
          medical <ENAMEX TYPE="PER_DESC">students</ENAMEX>. The course involves a total of almost
          <NUMEX TYPE="CARDINAL">700</NUMEX> <ENAMEX TYPE="PER_DESC">faculty members</ENAMEX>. <NUMEX TYPE="CARDINAL">One</NUMEX> or <NUMEX TYPE="CARDINAL">two</NUMEX> <ENAMEX TYPE="PER_DESC">faculty members</ENAMEX> at each
          site function as site <ENAMEX TYPE="PER_DESC">director</ENAMEX>(s) and are intimately
          involved in teaching the <ENAMEX TYPE="PER_DESC">students</ENAMEX> and organizing other
          <ENAMEX TYPE="PER_DESC">faculty</ENAMEX> to teach in the course.
          Teaching sessions are organized by organ system.
          <ENAMEX TYPE="PER_DESC">Students</ENAMEX> first learn skills by practicing on each other
          and by taking histories and performing physical
          examinations on selected <ENAMEX TYPE="PER_DESC">patients</ENAMEX>. <TIMEX TYPE="DATE">Each year</TIMEX>,
          <NUMEX TYPE="PERCENT">approximately</NUMEX> <TIMEX TYPE="DATE">130</TIMEX> medical <ENAMEX TYPE="PER_DESC">students</ENAMEX> and <NUMEX TYPE="CARDINAL">30</NUMEX> dental students
          participate in the course. Site <ENAMEX TYPE="PER_DESC">directors</ENAMEX> meet <TIMEX TYPE="DATE">monthly</TIMEX> as
          a <ENAMEX TYPE="ORG_DESC">group</ENAMEX> to determine the curriculum, teaching techniques,
          and evaluation of the course.
        
        
          Objective structured clinical examination
          (<ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>)
          
            Development
            We developed our OSCE primarily for educational
            purposes: to identify skills that each <ENAMEX TYPE="PER_DESC">student</ENAMEX> has
            learned well and those that need improvement during the
            final portion of the course. Performance on the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> is
            not formally factored into a <ENAMEX TYPE="PER_DESC">student</ENAMEX>'s grade for the
            course, but individual <ENAMEX TYPE="PER_DESC">student</ENAMEX> OSCE scores are reviewed
            by site <ENAMEX TYPE="PER_DESC">directors</ENAMEX>.
            We designed the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> in <TIMEX TYPE="DATE">1994</TIMEX>, pilot-tested
            them at evaluation sessions held in <TIMEX TYPE="DATE">1995 and 1996</TIMEX>, and
            reported on our results for <TIMEX TYPE="DATE">1996</TIMEX> [ <TIMEX TYPE="DATE">23</TIMEX> ] . Following
            established methods [ <ENAMEX TYPE="LAW">7 24 25</ENAMEX> ] , the course director
            and a <ENAMEX TYPE="ORG_DESC">committee</ENAMEX> of site <ENAMEX TYPE="PER_DESC">directors</ENAMEX> and <NUMEX TYPE="MONEY">4 th</NUMEX>-year student
            <ENAMEX TYPE="PER_DESC">representatives</ENAMEX> developed case scenarios, detailed
            instructions and checklists consisting of questions or
            tasks for <NUMEX TYPE="CARDINAL">16</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> focused on specific clinical
            <ENAMEX TYPE="FAC_DESC">areas</ENAMEX>. <TIMEX TYPE="DATE">From 1994-1996</TIMEX>, we refined the content of the
            <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX> and the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> <ENAMEX TYPE="ORG_DESC">organization</ENAMEX> through frequent
            discussions with all site <ENAMEX TYPE="PER_DESC">directors</ENAMEX> and through
            feedback from <ENAMEX TYPE="PER_DESC">students</ENAMEX> and <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> preceptors. We made no
            changes to the exam during <TIMEX TYPE="DATE">1997-1999</TIMEX>. Site directors
            determined that all OSCE questions reflected essential
            skills to be mastered by second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX>. We did
            not weight OSCE questions, <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> or skills according
            to degree of difficulty. <TIMEX TYPE="DATE">Annual</TIMEX> feedback from <ENAMEX TYPE="PER_DESC">students</ENAMEX>
            and <ENAMEX TYPE="PER_DESC">faculty</ENAMEX> endorsed the face validity of the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>. In
            <TIMEX TYPE="DATE">1999</TIMEX>, <NUMEX TYPE="PERCENT">90%</NUMEX> of <ENAMEX TYPE="PER_DESC">students</ENAMEX> and <NUMEX TYPE="PERCENT">91%</NUMEX> of <ENAMEX TYPE="PER_DESC">faculty</ENAMEX> agreed that
            the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> represented an appropriate and fair evaluation
            method, and that enough time was given to complete the
            <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>.
            In the <NUMEX TYPE="CARDINAL">16</NUMEX>-station <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, <NUMEX TYPE="CARDINAL">nine</NUMEX> different formats were
            used alone or in combination: question and answer,
            <ENAMEX TYPE="ORGANIZATION">preceptor</ENAMEX> role play, standardized <ENAMEX TYPE="PER_DESC">patients</ENAMEX>, actual
            <ENAMEX TYPE="PER_DESC">patients</ENAMEX>, mechanical or structural <ENAMEX TYPE="PER_DESC">models</ENAMEX>, <NUMEX TYPE="CARDINAL">35</NUMEX><ENAMEX TYPE="PRODUCT">-mm</ENAMEX>
            slides, audiotape, videotape, and CD-ROM (<ENAMEX TYPE="PRODUCT">Table 1</ENAMEX>).
            <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> <ENAMEX TYPE="ORG_DESC">committee</ENAMEX> <ENAMEX TYPE="PER_DESC">members</ENAMEX> designated each question or task
            in the <NUMEX TYPE="CARDINAL">16</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> as one of <NUMEX TYPE="CARDINAL">7</NUMEX> clinical skills, defined
            as follows: asking appropriate questions for the
            history (history-taking); performing the physical
            examination correctly (physical examination technique);
            understanding the pathophysiology of physical findings
            (physical examination knowledge); identifying
            abnormalities on physical examination (identification
            of abnormalities); developing appropriate differential
            diagnoses for the clinical information obtained
            (differential diagnosis); utilizing appropriate
            <ENAMEX TYPE="PER_DESC">patient-doctor</ENAMEX> interaction techniques (patient
            <ENAMEX TYPE="ORGANIZATION">interaction</ENAMEX>); and orally presenting the history and
            differential diagnosis after taking a clinical history
            (patient presentation). The total number of OSCE
            questions <TIMEX TYPE="DATE">each year</TIMEX> was <NUMEX TYPE="CARDINAL">382</NUMEX>, and the mean number of
            questions per skill was <NUMEX TYPE="MONEY">55</NUMEX> (range <NUMEX TYPE="CARDINAL">14-70</NUMEX>), evenly
            distributed except for <ENAMEX TYPE="PER_DESC">patient</ENAMEX> interaction and patient
            presentation.
          
          
            Implementation
            <TIMEX TYPE="DATE">Each year</TIMEX>, we held <NUMEX TYPE="CARDINAL">10</NUMEX> sessions of the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> on <TIMEX TYPE="DATE">3 days</TIMEX>
            (<TIMEX TYPE="DATE">Monday</TIMEX>, <TIMEX TYPE="DATE">Wednesday</TIMEX> and <TIMEX TYPE="DATE">Friday</TIMEX> <TIMEX TYPE="TIME">afternoons</TIMEX>) during a
            <TIMEX TYPE="DATE">one-week</TIMEX> period in <TIMEX TYPE="DATE">April</TIMEX> for all second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX>.
            <NUMEX TYPE="CARDINAL">Two</NUMEX> consecutive, <TIMEX TYPE="TIME">early and late afternoon</TIMEX> sessions each
            consisted of the same <NUMEX TYPE="CARDINAL">16</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> and lasted <TIMEX TYPE="TIME">2.5 hours</TIMEX>.
            To accommodate all <ENAMEX TYPE="PER_DESC">students</ENAMEX>, sessions were conducted
            simultaneously on <NUMEX TYPE="CARDINAL">2</NUMEX> <ENAMEX TYPE="FAC_DESC">floors</ENAMEX> of the medical <ENAMEX TYPE="ORG_DESC">school</ENAMEX>'s
            education <ENAMEX TYPE="ORG_DESC">center</ENAMEX>, for a total of <NUMEX TYPE="CARDINAL">10</NUMEX> <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> sessions.
            Other than by <TIMEX TYPE="DATE">date</TIMEX> and time, the sessions varied only
            in the assignment of preceptors. With the help of
            <ENAMEX TYPE="ORGANIZATION">guides</ENAMEX>, timers and a strict schedule, <ENAMEX TYPE="PER_DESC">students</ENAMEX> rotated
            through the <NUMEX TYPE="CARDINAL">16</NUMEX> clinical <ENAMEX TYPE="FAC_DESC">stations</ENAMEX>, each precepted by a
            <ENAMEX TYPE="PER_DESC">faculty member</ENAMEX>. All preceptors received standardized
            guidelines for checklists and feedback prior to each
            <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> session, as did the standardized <ENAMEX TYPE="PER_DESC">patients</ENAMEX> or
            <ENAMEX TYPE="PER_DESC">actors</ENAMEX> for the abdominal pain, alcohol/abdominal exam,
            knee and thyroid <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>. <NUMEX TYPE="CARDINAL">Fourteen</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> were each
            <TIMEX TYPE="TIME">6 minutes</TIMEX> in duration, and <NUMEX TYPE="CARDINAL">two</NUMEX> - abdominal pain and
            headache - were <TIMEX TYPE="TIME">12 minutes</TIMEX> in duration.
            At each <ENAMEX TYPE="FAC_DESC">station</ENAMEX>, the student performed the indicated
            tasks for <NUMEX TYPE="CARDINAL">two-thirds</NUMEX> of the time, while the faculty
            <ENAMEX TYPE="PERSON">preceptor</ENAMEX> observed and checked off the tasks performed
            correctly, as defined by checklists, one for each
            student. All tasks performed or questions answered by
            each <ENAMEX TYPE="PER_DESC">student</ENAMEX> were scored dichotomously as correct (<ENAMEX TYPE="CONTACT_INFO">1</ENAMEX>)
            or left blank (<ENAMEX TYPE="CONTACT_INFO">0</ENAMEX>) on the checklists. During the final
            <NUMEX TYPE="CARDINAL">one-third</NUMEX> of time at each <ENAMEX TYPE="FAC_DESC">station</ENAMEX>, the preceptor
            provided feedback on the <ENAMEX TYPE="PER_DESC">student</ENAMEX>'s performance, as
            advocated by others [ <TIMEX TYPE="DATE">26</TIMEX> ] . <TIMEX TYPE="DATE">Each year</TIMEX>, approximately
            <NUMEX TYPE="CARDINAL">150</NUMEX> <ENAMEX TYPE="PER_DESC">preceptors</ENAMEX> participated in the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, and <NUMEX TYPE="PERCENT">60%</NUMEX> have
            had experience with this <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> and the checklists from
            <TIMEX TYPE="DATE">prior years</TIMEX>.
          
        
        
          <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> collection and analysis
          Correct answers to all OSCE questions were recorded on
          checklists by preceptors, double-entered by research
          staff into an <ENAMEX TYPE="ORGANIZATION">ASCII</ENAMEX> file, and analyzed in <ENAMEX TYPE="ORGANIZATION">SPSS</ENAMEX> [ <TIMEX TYPE="DATE">27</TIMEX> ] .
          Total <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, skill and <ENAMEX TYPE="FAC_DESC">station</ENAMEX> scores were calculated as
          follows. Each task or question counted <NUMEX TYPE="CARDINAL">one</NUMEX> point, and the
          sum of tasks performed or questions answered correctly
          for each <ENAMEX TYPE="FAC_DESC">station</ENAMEX> was designated the <ENAMEX TYPE="ORG_DESC">station</ENAMEX> score. The
          sum of station <ENAMEX TYPE="PER_DESC">scores</ENAMEX> produced a total OSCE score for
          each <ENAMEX TYPE="PER_DESC">student</ENAMEX>. Means of <ENAMEX TYPE="PER_DESC">students</ENAMEX>' scores ± <NUMEX TYPE="CARDINAL">one</NUMEX> standard
          deviation for each of the <NUMEX TYPE="CARDINAL">16</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> were computed. To
          compute the skills score, each task or question on the
          checklist for every <ENAMEX TYPE="FAC_DESC">station</ENAMEX> was designated as one of <NUMEX TYPE="CARDINAL">7</NUMEX>
          skills. The sum of tasks performed or questions answered
          correctly for each skill produced a <ENAMEX TYPE="PER_DESC">student</ENAMEX>'s skill
          score. Means of <ENAMEX TYPE="PER_DESC">students</ENAMEX>' scores for each of the <NUMEX TYPE="CARDINAL">7</NUMEX> skills
          were computed. We combined the data from the <TIMEX TYPE="DATE">1997, 1998</TIMEX>
          and <TIMEX TYPE="DATE">1999</TIMEX> <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>'s.
          Total OSCE score, scores for each clinical skill, and
          scores for each <ENAMEX TYPE="FAC_DESC">station</ENAMEX> were the primary outcome
          variables. In addition to the checklists completed by
          <ENAMEX TYPE="PER_DESC">faculty preceptors</ENAMEX> at each <ENAMEX TYPE="FAC_DESC">station</ENAMEX> for each <ENAMEX TYPE="PER_DESC">student</ENAMEX>, we
          collected data on <ENAMEX TYPE="PER_DESC">student</ENAMEX>, preceptor and examination
          variables to examine factors that might predict <ENAMEX TYPE="PER_DESC">students</ENAMEX>'
          OSCE scores. Student variables were type of student
          (medical or dental), and teaching site (<ENAMEX TYPE="PRODUCT">Site A-I</ENAMEX>). The
          preceptor variables were the floor (<NUMEX TYPE="ORDINAL">first</NUMEX> or <NUMEX TYPE="ORDINAL">third</NUMEX>) and
          session <ENAMEX TYPE="ORG_DESC">group</ENAMEX> (<TIMEX TYPE="TIME">early or late afternoon</TIMEX>) assigned to each
          <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> preceptor. Examination variables consisted of OSCE
          <TIMEX TYPE="DATE">year</TIMEX> (<TIMEX TYPE="DATE">1997, 1998 or 1999</TIMEX>), <TIMEX TYPE="DATE">the day</TIMEX> each <ENAMEX TYPE="PER_DESC">student</ENAMEX> took the
          <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> (<NUMEX TYPE="ORDINAL">first</NUMEX>, <NUMEX TYPE="ORDINAL">second</NUMEX> or <NUMEX TYPE="ORDINAL">third</NUMEX>), and sequence of
          <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>.
          For all predictor variables, total OSCE, skill and
          station score means were compared with one-way <ENAMEX TYPE="ORGANIZATION">ANOVA</ENAMEX>.
          Predictor variables significantly associated at p <
          <NUMEX TYPE="CARDINAL">.05</NUMEX> with <ENAMEX TYPE="PER_DESC">students</ENAMEX>' total OSCE in univariate analysis were
          entered into a linear regression model, with the single
          dependent variable being a <ENAMEX TYPE="PER_DESC">student</ENAMEX>'s total OSCE score.
          The predictor variables were also entered into <NUMEX TYPE="CARDINAL">two</NUMEX>
          multivariate analysis of variance (MANOVA) models, each
          of which included multiple dependent variables. As
          dependent variables, <NUMEX TYPE="CARDINAL">one</NUMEX> model used clinical skill
          scores, and the <NUMEX TYPE="ORDINAL">second</NUMEX> model used station <ENAMEX TYPE="PER_DESC">scores</ENAMEX>.
          Separate <ENAMEX TYPE="PRODUCT_DESC">models</ENAMEX> were used due to the high co-linearity
          between the skill and station <ENAMEX TYPE="PER_DESC">scores</ENAMEX>, since both of these
          scores drew from the same item pool. <ENAMEX TYPE="ORGANIZATION">P</ENAMEX>-values within <TIMEX TYPE="TIME">each</TIMEX>
          <ENAMEX TYPE="ORGANIZATION">MANOVA</ENAMEX> <ENAMEX TYPE="PRODUCT_DESC">model</ENAMEX> were adjusted for multiple comparisons. In
          addition, we set the threshold for judging statistical
          significance at <ENAMEX TYPE="ORGANIZATION">p <</ENAMEX>= <NUMEX TYPE="CARDINAL">.001</NUMEX> to further reduce the
          influence of multiple comparisons on p values.
          Because it was not logistically possible to obtain
          <ENAMEX TYPE="ORGANIZATION">inter</ENAMEX>-rater reliability due to the large number of
          preceptors, we used generalizability theory analysis [ <NUMEX TYPE="CARDINAL">28</NUMEX>
          ] . This analysis accounts statistically for rater error
          by parsing out the variance relevant to the instrument in
          question. By modeling the variances as separate
          <ENAMEX TYPE="PERSON">characteristics</ENAMEX>, we isolated the variance due to student
          ability, which in classical test theory is equivalent to
          true score variance. Other variances related to the test
          are treated as error variances. In this framework, we
          treated error due to differences in raters as error
          <ENAMEX TYPE="ORGANIZATION">variance</ENAMEX>.
          We calculated the <ENAMEX TYPE="PRODUCT">Kuder-Richardson-20</ENAMEX> coefficient of
          reliability, <ENAMEX TYPE="PRODUCT">KR-20</ENAMEX>, for the total OSCE score, clinical
          skill and station <ENAMEX TYPE="PER_DESC">scores</ENAMEX>. The <ENAMEX TYPE="PRODUCT">KR-20</ENAMEX> [ <TIMEX TYPE="DATE">29</TIMEX> ] is used for
          binary items and is comparable to <ENAMEX TYPE="ORGANIZATION">Cronbach</ENAMEX>'s alpha. This
          measure of internal consistency is the best measure of
          <ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX> when there are many more than <NUMEX TYPE="CARDINAL">two</NUMEX> raters. It
          is equivalent to the generalizability or <ENAMEX TYPE="ORGANIZATION">G</ENAMEX> coefficient
          which examines total scale scores across raters in a
          D-study scenario (total scores are normally distributed),
          when the main effect variance due to raters is assumed to
          be <NUMEX TYPE="CARDINAL">zero</NUMEX> [ <NUMEX TYPE="CARDINAL">30 31 32</NUMEX> ] . In our study, we assumed zero
          main-effect variance to be the average across the large
          <ENAMEX TYPE="GAME">pool</ENAMEX> of student raters, because <ENAMEX TYPE="PER_DESC">student</ENAMEX> assignment to a
          preceptor for any given <ENAMEX TYPE="ORG_DESC">station</ENAMEX> was essentially
          <ENAMEX TYPE="ORGANIZATION">random</ENAMEX>.
        
      
      
        Results
        Over <TIMEX TYPE="DATE">three years</TIMEX>, <NUMEX TYPE="CARDINAL">489</NUMEX> second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX> (<NUMEX TYPE="CARDINAL">402</NUMEX> medical
        and <NUMEX TYPE="CARDINAL">87</NUMEX> dental) and <NUMEX TYPE="CARDINAL">445</NUMEX> <ENAMEX TYPE="PER_DESC">faculty</ENAMEX> participated in the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> for
        second-year physical diagnosis course. <ENAMEX TYPE="PER_DESC">Students</ENAMEX> answered
        slightly more than half of all the OSCE items correctly,
        <NUMEX TYPE="PERCENT">57% ± 6%</NUMEX> (Figure <NUMEX TYPE="CARDINAL">1a</NUMEX>), with almost no change over <TIMEX TYPE="DATE">3 years</TIMEX> (p
        = <NUMEX TYPE="CARDINAL">.28</NUMEX>). Individual <ENAMEX TYPE="PER_DESC">student scores</ENAMEX> on the entire <ENAMEX TYPE="SUBSTANCE">OSCE</ENAMEX> ranged
        from <NUMEX TYPE="PERCENT">39% to 75%</NUMEX>.
        For clinical skills, <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored highest on patient
        <ENAMEX TYPE="ORGANIZATION">interaction</ENAMEX> (<NUMEX TYPE="PERCENT">72%</NUMEX>), followed by physical examination
        <ENAMEX TYPE="PERSON">technique</ENAMEX> (<NUMEX TYPE="PERCENT">65%</NUMEX>), identification of abnormalities (<NUMEX TYPE="PERCENT">62%</NUMEX>),
        history-taking (<NUMEX TYPE="PERCENT">60%</NUMEX>), <ENAMEX TYPE="PER_DESC">patient</ENAMEX> presentation (<NUMEX TYPE="PERCENT">60%</NUMEX>), physical
        examination knowledge (<NUMEX TYPE="PERCENT">47%</NUMEX>), and differential diagnosis
        (<NUMEX TYPE="PERCENT">40%</NUMEX>) (p <NUMEX TYPE="MONEY">< .0001</NUMEX>, Figure <NUMEX TYPE="CARDINAL">1a</NUMEX>). Clinical skill scores
        remained stable from <TIMEX TYPE="DATE">1997-1999</TIMEX>, with only slight
        improvement in history-taking (<NUMEX TYPE="PERCENT">3%</NUMEX> from <TIMEX TYPE="DATE">1997 to 1999</TIMEX>, p =
        <NUMEX TYPE="MONEY">.0003</NUMEX>).
        For <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>, <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored highest on the
        <ENAMEX TYPE="ORGANIZATION">arthritis</ENAMEX> (<NUMEX TYPE="PERCENT">70%</NUMEX>), ear (<NUMEX TYPE="PERCENT">69%</NUMEX>), <ENAMEX TYPE="DISEASE">breast</ENAMEX> (<NUMEX TYPE="PERCENT">69%</NUMEX>) and thyroid
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX> (<NUMEX TYPE="PERCENT">64%</NUMEX>), and lowest on the <ENAMEX TYPE="PER_DESC">rectal</ENAMEX>/prostate (<NUMEX TYPE="PERCENT">51%</NUMEX>),
        mental status (<NUMEX TYPE="PERCENT">48%</NUMEX>), hemoptysis (<NUMEX TYPE="PERCENT">47%</NUMEX>) and calf pain
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX> (<NUMEX TYPE="PERCENT">29%</NUMEX>) (p <NUMEX TYPE="MONEY">< .0001</NUMEX>, Figure <NUMEX TYPE="CARDINAL">1b</NUMEX>). We found
        statistically significant year-to-year differences among
        the means for <NUMEX TYPE="CARDINAL">10</NUMEX> of <NUMEX TYPE="CARDINAL">16</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>. However, absolute
        differences were small; the largest differences were <NUMEX TYPE="PERCENT">10%</NUMEX>
        for the skin and mental status <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> (data not
        shown).
        When we examined the mean total, clinical skill and
        station scores according to <ENAMEX TYPE="PER_DESC">student</ENAMEX>, preceptor and
        examination variables, we found many statistically
        significant <ENAMEX TYPE="ORG_DESC">associations</ENAMEX> in the univariate analyses.
        Multivariable analyses yielded fewer but still similarly
        significant results. <ENAMEX TYPE="PRODUCT">Table 2presents</ENAMEX> the highest scoring
        <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> of predictor variables and the largest adjusted
        differences between the highest scoring and the reference
        <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>.
        For adjusted total OSCE scores, medical <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored
        <NUMEX TYPE="PERCENT">6%</NUMEX> higher than dental <ENAMEX TYPE="PER_DESC">students</ENAMEX>, <NUMEX TYPE="PERCENT">57%</NUMEX> vs. <NUMEX TYPE="PERCENT">51%</NUMEX> (p <NUMEX TYPE="MONEY">< .0001</NUMEX>,
        <ENAMEX TYPE="CONTACT_INFO">Table 2</ENAMEX>). No other variable was found to predict total OSCE
        scores. For adjusted clinical skill scores, the largest
        score differences were associated with the student variable
        - medical vs. dental. Medical <ENAMEX TYPE="PER_DESC">students</ENAMEX>' scores were <NUMEX TYPE="PERCENT">9%</NUMEX>
        higher than dental <ENAMEX TYPE="PER_DESC">students</ENAMEX>' scores for patient
        <ENAMEX TYPE="PERSON">presentation</ENAMEX> (and were slightly but significantly higher
        for all other clinical skills except history-taking, not
        shown). <ENAMEX TYPE="PRODUCT">Table 2shows</ENAMEX> other significant differences among
        several tested variables and <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>, but the absolute score
        differences for these variables were relatively small, <NUMEX TYPE="PERCENT">8%</NUMEX>
        or less.
        Adjusted station <ENAMEX TYPE="PER_DESC">scores</ENAMEX> demonstrated the largest
        differences, notably for teaching sites (<ENAMEX TYPE="PRODUCT">Table 2</ENAMEX>). For the
        <ENAMEX TYPE="ORGANIZATION">thyroid</ENAMEX> <ENAMEX TYPE="ORG_DESC">station</ENAMEX>, the scores of <ENAMEX TYPE="PER_DESC">students</ENAMEX> at site H were <NUMEX TYPE="PERCENT">28%</NUMEX>
        higher than <ENAMEX TYPE="PER_DESC">scores</ENAMEX> for <ENAMEX TYPE="PER_DESC">students</ENAMEX> at reference site <ENAMEX TYPE="PERSON">I. Other</ENAMEX>
        predictor variables accounted for smaller differences.
        Medical <ENAMEX TYPE="PER_DESC">students</ENAMEX>' adjusted scores on the <ENAMEX TYPE="PER_DESC">rectal</ENAMEX>/prostate
        station were <NUMEX TYPE="PERCENT">15%</NUMEX> higher than dental <ENAMEX TYPE="PER_DESC">students</ENAMEX>' scores. They
        were also significantly - but <NUMEX TYPE="PERCENT">less than 10%</NUMEX> - higher for <NUMEX TYPE="CARDINAL">8</NUMEX>
        other <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>, and no different for <NUMEX TYPE="CARDINAL">7</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> (not
        shown). Other variables - preceptor <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>, OSCE day and
        OSCE year - also demonstrated some variation, with the
        largest differences being <NUMEX TYPE="PERCENT">14%</NUMEX> among preceptor <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> for
        the knee <ENAMEX TYPE="FAC_DESC">station</ENAMEX>.
        Because teaching sites demonstrated the greatest
        differences in <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> station <ENAMEX TYPE="PER_DESC">scores</ENAMEX>, even after adjustment
        for other variables, we examined detailed inter-site
        differences (<ENAMEX TYPE="PRODUCT">Table 3</ENAMEX>). <TIMEX TYPE="DATE">Eight</TIMEX> adjusted station <ENAMEX TYPE="PER_DESC">scores</ENAMEX> showed
        substantial and significant differences in student scores
        among teaching sites: thyroid (<NUMEX TYPE="PERCENT">28%</NUMEX>), knee (<NUMEX TYPE="PERCENT">26%</NUMEX>), ear (<NUMEX TYPE="PERCENT">23%</NUMEX>),
        <ENAMEX TYPE="ORGANIZATION">arthritis</ENAMEX> (<NUMEX TYPE="PERCENT">17%</NUMEX>), heart (<NUMEX TYPE="PERCENT">13%</NUMEX>), mental status (<NUMEX TYPE="PERCENT">11%</NUMEX>), lung
        (<NUMEX TYPE="PERCENT">11%</NUMEX>) and skin (<NUMEX TYPE="PERCENT">10%</NUMEX>) (<ENAMEX TYPE="PRODUCT_DESC">p <</ENAMEX>= <NUMEX TYPE="CARDINAL">.001</NUMEX>). There were no
        significant inter-site differences for the <ENAMEX TYPE="DISEASE">breast</ENAMEX>,
        abdominal pain, presentation, headache, alcohol/abdominal
        <ENAMEX TYPE="PERSON">exam</ENAMEX>, <ENAMEX TYPE="PER_DESC">rectal</ENAMEX>/prostate, hemoptysis and calf pain <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>.
        At every teaching site, adjusted scores for <NUMEX TYPE="CARDINAL">1</NUMEX> or <NUMEX TYPE="CARDINAL">2</NUMEX> stations
        were higher than at reference site I, while <ENAMEX TYPE="PER_DESC">scores</ENAMEX> for <NUMEX TYPE="CARDINAL">1</NUMEX> to
        <NUMEX TYPE="CARDINAL">3</NUMEX> other <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> were lower than those for the reference
        site.
        The overall reliability coefficient for the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> of <NUMEX TYPE="CARDINAL">382</NUMEX>
        items was <NUMEX TYPE="MONEY">.86</NUMEX> (<ENAMEX TYPE="PRODUCT">Table 3</ENAMEX>), indicating good reliability of the
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> total score [ <NUMEX TYPE="CARDINAL">25 31 32</NUMEX> ] . The reliabilities of the
        clinical skill scores ranged from <NUMEX TYPE="MONEY">.57 to .77</NUMEX> (not shown).
        All but one of these scores - identification of
        abnormalities, <NUMEX TYPE="CARDINAL">.57</NUMEX> - had a reliability coefficient of <NUMEX TYPE="CARDINAL">.65</NUMEX>
        or higher. Reliabilities for clinical skill scores were
        generally higher than for station scores which ranged from
        <NUMEX TYPE="CARDINAL">.40</NUMEX> to <NUMEX TYPE="MONEY">.83</NUMEX> (<ENAMEX TYPE="PRODUCT">Table 3</ENAMEX>).
      
      
        Discussion
        In an OSCE for a second-year physical diagnosis course,
        we found a similar pattern of clinical skill acquisition
        for <NUMEX TYPE="CARDINAL">three</NUMEX> successive <ENAMEX TYPE="PER_DESC">classes</ENAMEX> of <ENAMEX TYPE="PER_DESC">students</ENAMEX>. <ENAMEX TYPE="PER_DESC">Students</ENAMEX>
        performed better on interpersonal and technical skills -
        <ENAMEX TYPE="PER_DESC">patient interaction</ENAMEX>, history-taking, physical examination
        <ENAMEX TYPE="PERSON">technique</ENAMEX>, identification of abnormality, and patient
        presentation - than on interpretative or integrative skills
        - knowledge of the pathophysiology of physical examination
        findings, and differential diagnosis. Teaching sites
        differed widely from one another in performance on
        <ENAMEX TYPE="ORGANIZATION">individual OSCE</ENAMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>, only modestly on clinical skills,
        and not at all on total OSCE scores. Medical <ENAMEX TYPE="PER_DESC">students</ENAMEX>
        scored somewhat better than dental <ENAMEX TYPE="PER_DESC">students</ENAMEX> on the overall
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, all clinical skills except history-taking, and almost
        half of the <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>.
        To our knowledge, this study is the <NUMEX TYPE="ORDINAL">first</NUMEX> to examine
        comprehensively student performance for general clinical
        <ENAMEX TYPE="PRODUCT">skills</ENAMEX> and specific <ENAMEX TYPE="SUBSTANCE">OSCE</ENAMEX> <ENAMEX TYPE="FAC_DESC">stations</ENAMEX> at the second-year
        student level. Other studies of <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>'s for second-year
        <ENAMEX TYPE="PER_DESC">students</ENAMEX> have focused on specific skills or content [ <NUMEX TYPE="CARDINAL">8 9</NUMEX>
        <NUMEX TYPE="CARDINAL">10 11</NUMEX> ] , or logistics and psychometrics [ <ENAMEX TYPE="LAW">7 12 16</ENAMEX> ] . None
        of the other studies employed multivariable analysis in
        examining factors associated with <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> performance. By
        including such analysis, we were able to hold <ENAMEX TYPE="PER_DESC">student</ENAMEX> and
        examination variables constant in order to determine what
        parts of the curriculum <ENAMEX TYPE="PER_DESC">students</ENAMEX> mastered best and which
        sites best taught specific physical diagnosis content.
        Higher scores on technical and patient interaction
        <ENAMEX TYPE="PRODUCT">skills</ENAMEX>, compared to integrative skills, are not surprising.
        <ENAMEX TYPE="PER_DESC">Students</ENAMEX> at <ENAMEX TYPE="ORGANIZATION">Harvard</ENAMEX> and in many medical <ENAMEX TYPE="ORG_DESC">schools</ENAMEX> begin to
        practice some interviewing, history-taking and patient
        <ENAMEX TYPE="ORGANIZATION">interaction</ENAMEX> during <TIMEX TYPE="DATE">the first year</TIMEX> curriculum, and they
        spend the entire second-year physical diagnosis course
        learning the techniques of physical examination.
        <ENAMEX TYPE="PER_DESC">Investigators</ENAMEX> have reported similar results in other
        settings. OSCE scores among clinical <ENAMEX TYPE="PER_DESC">clerks</ENAMEX> were higher on
        history-taking/physical examination skills (mean score ±
        s.d., <NUMEX TYPE="CARDINAL">61</NUMEX> ± <NUMEX TYPE="PERCENT">4%</NUMEX>) and interviewing skills (<NUMEX TYPE="CARDINAL">69</NUMEX> ± <NUMEX TYPE="PERCENT">11%</NUMEX>), and
        lower on problem solving (<NUMEX TYPE="CARDINAL">50</NUMEX> ± <NUMEX TYPE="PERCENT">6%</NUMEX>) skills [ <TIMEX TYPE="DATE">33</TIMEX> ] . In a
        non-OS <ENAMEX TYPE="LAW">CE</ENAMEX> examination using patient management problems,
        second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored <NUMEX TYPE="CARDINAL">70</NUMEX> ± <NUMEX TYPE="PERCENT">9%</NUMEX> on history, <NUMEX TYPE="CARDINAL">66</NUMEX> ± <NUMEX TYPE="PERCENT">10%</NUMEX> on
        physical examination, and <NUMEX TYPE="CARDINAL">40</NUMEX> ± <NUMEX TYPE="PERCENT">15%</NUMEX> on diagnosis [ <TIMEX TYPE="DATE">34</TIMEX> ] .
        However, in an OSCE for a second-year neurology skills
        course, this pattern did not hold: interpretative skill
        scores (<NUMEX TYPE="CARDINAL">76</NUMEX> ± <NUMEX TYPE="PERCENT">16%</NUMEX>) were higher than technical performance
        scores (<NUMEX TYPE="CARDINAL">67</NUMEX> ± <NUMEX TYPE="PERCENT">17%</NUMEX>), but no significance testing was reported
        [ <TIMEX TYPE="DATE">15</TIMEX> ] .
        Differential diagnosis has traditionally been considered
        a secondary goal of our physical diagnosis course, so
        performance might be expected to be lower. However,
        pathophysiology of <ENAMEX TYPE="DISEASE">disease</ENAMEX> is a major focus of the
        second-year curriculum. Lower performance in knowledge of
        the pathophysiology related to physical diagnosis, compared
        with technical performance of the physical examination,
        suggests that improvements integrating pathophysiology into
        the teaching of the history and physical examination are
        needed.
        Our other key finding was the variable performance by
        <ENAMEX TYPE="PER_DESC">students</ENAMEX> from different teaching <ENAMEX TYPE="FAC_DESC">sites</ENAMEX> on <NUMEX TYPE="CARDINAL">half</NUMEX> the OSCE
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>, despite similar performance by <ENAMEX TYPE="FAC_DESC">sites</ENAMEX> on the
        overall OSCE. Every site scored highest or next-to-highest
        on <NUMEX TYPE="CARDINAL">at least one</NUMEX> <ENAMEX TYPE="FAC_DESC">station</ENAMEX>, and every <ENAMEX TYPE="FAC_DESC">site</ENAMEX> also scored lowest
        or next-to-lowest among <ENAMEX TYPE="FAC_DESC">sites</ENAMEX> on <NUMEX TYPE="CARDINAL">at least one</NUMEX> <ENAMEX TYPE="FAC_DESC">station</ENAMEX>.
        Because of the large numbers of <ENAMEX TYPE="PER_DESC">students</ENAMEX> in this study,
        even differences of <NUMEX TYPE="PERCENT">2%</NUMEX> were statistically significant, but
        we consider differences <NUMEX TYPE="PERCENT">greater than 10%</NUMEX> to be
        educationally significant and worthy of targeted
        improvement efforts.
        We found the largest differences for the thyroid, knee,
        <ENAMEX TYPE="PRODUCT">ear</ENAMEX>, <ENAMEX TYPE="DISEASE">arthritis</ENAMEX>, heart, lung, mental status, and skin
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>. While <ENAMEX TYPE="PER_DESC">students</ENAMEX> may have acquired overall physical
        diagnosis skills similarly from site to site, our results
        suggest they did not learn equally at every site the skills
        required for adequate examination or understanding of these
        specific organ systems. <ENAMEX TYPE="ORGANIZATION">Inter</ENAMEX>-site differences in
        content-specific station <ENAMEX TYPE="PER_DESC">scores</ENAMEX> represent opportunities for
        teaching sites to learn from one another, using strategies
        such as structured clinical instruction modules [ <ENAMEX TYPE="LAW">9 35</ENAMEX> ] or
        reinforced practice [ <TIMEX TYPE="DATE">11</TIMEX> ] and developing more uniform
        learning objectives and curriculum.
        Raw score results at <NUMEX TYPE="CARDINAL">one</NUMEX> medical school must be
        interpreted with caution, since <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>'s at other <ENAMEX TYPE="ORG_DESC">schools</ENAMEX> may
        differ in degree of difficulty. The mean total OSCE score
        of <NUMEX TYPE="PERCENT">57% ± 6%</NUMEX> in our study compares favorably with results
        from <NUMEX TYPE="CARDINAL">one</NUMEX> report on second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX> (<NUMEX TYPE="CARDINAL">52</NUMEX> ± <NUMEX TYPE="PERCENT">6%</NUMEX>) [ <TIMEX TYPE="DATE">36</TIMEX> ] ,
        a report on clinical <ENAMEX TYPE="PER_DESC">clerks</ENAMEX> (<NUMEX TYPE="CARDINAL">57</NUMEX> ± <NUMEX TYPE="PERCENT">4%</NUMEX>) [ <TIMEX TYPE="DATE">33</TIMEX> ] , and a study
        of third-year medicine <ENAMEX TYPE="PER_DESC">students</ENAMEX> (<NUMEX TYPE="PERCENT">58%</NUMEX>) [ <ENAMEX TYPE="LAW">3</ENAMEX> ] , but less
        favorably with another report on second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX>, <NUMEX TYPE="PERCENT">70%</NUMEX>
        [ <TIMEX TYPE="DATE">12</TIMEX> ] . None of these studies adjusted their student
        scores.
        Consistent with a prior study from the <ENAMEX TYPE="GPE">U.K.</ENAMEX> [ <TIMEX TYPE="DATE">37</TIMEX> ] , we
        found that dental <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored lower than medical
        <ENAMEX TYPE="PER_DESC">students</ENAMEX>, but not at a level which raises serious concerns
        about their participation in the physical diagnosis course.
        While dental <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored lower on the majority of
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>, they performed as well as medical <ENAMEX TYPE="PER_DESC">students</ENAMEX> on
        some <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> with content that is not related to their
        <ENAMEX TYPE="ORGANIZATION">ultimate</ENAMEX> professional focus, such as <ENAMEX TYPE="DISEASE">breast</ENAMEX>, mental status
        and abdominal pain.
        This study has several limitations. We have not directly
        assessed inter-rater reliability because of logistical and
        cost constraints. To address this methodological <ENAMEX TYPE="ORG_DESC">concern</ENAMEX>,
        we used generalizibility theory (GT) to produce a measure
        of reliability similar in quality to inter-rater
        <ENAMEX TYPE="ORGANIZATION">reliability</ENAMEX> [ <TIMEX TYPE="DATE">32</TIMEX> ] .
        There are a number of examples of the use of <ENAMEX TYPE="ORGANIZATION">GT</ENAMEX> to
        account statistically for rater error [ <NUMEX TYPE="CARDINAL">32 38 39 40</NUMEX> ] .
        Using <ENAMEX TYPE="ORGANIZATION">GT</ENAMEX> can also overcome some problems inherent in
        <ENAMEX TYPE="ORGANIZATION">inter</ENAMEX>-rater reliability, such as overestimating reliability
        [ <TIMEX TYPE="DATE">41</TIMEX> ] . Due to the large number of preceptors involved in
        our <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, we made the statistically reasonable assumption
        that any error due to rater differences is randomly
        distributed. Since randomly distributed error has a mean of
        <ENAMEX TYPE="PERSON">zero</ENAMEX>, the error variance due to differences among all
        <ENAMEX TYPE="ORGANIZATION">preceptors</ENAMEX> is <NUMEX TYPE="CARDINAL">zero</NUMEX>. In our <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>, the variation of
        individual <ENAMEX TYPE="PER_DESC">raters</ENAMEX> around the mean <ENAMEX TYPE="FAC_DESC">station</ENAMEX> score of all
        <ENAMEX TYPE="ORGANIZATION">raters</ENAMEX> is very close to <NUMEX TYPE="MONEY">0</NUMEX> (e.g., <NUMEX TYPE="CARDINAL">.04</NUMEX> for the presentation
        <ENAMEX TYPE="ORGANIZATION">station</ENAMEX>, data not shown), and the standard deviations of
        student scores are comparatively large (e.g., <NUMEX TYPE="CARDINAL">15</NUMEX> for the
        presentation <ENAMEX TYPE="ORG_DESC">station</ENAMEX>). Finally, our <ENAMEX TYPE="GPE">GT</ENAMEX>-based assumption is
        especially appropriate when the test scores used in the
        analysis are created by summing many items across each
        scale. <ENAMEX TYPE="ORGANIZATION">Summing</ENAMEX> in this fashion has the effect of further
        randomizing the error variance. The reliability, or
        <ENAMEX TYPE="ORGANIZATION">internal</ENAMEX> consistency, of the overall OSCE was good at <NUMEX TYPE="CARDINAL">.86</NUMEX>.
        The reliability of <NUMEX TYPE="CARDINAL">6</NUMEX> of <NUMEX TYPE="CARDINAL">7</NUMEX> skill scores, and <NUMEX TYPE="CARDINAL">9</NUMEX> of <NUMEX TYPE="CARDINAL">16</NUMEX> station
        scores, were acceptable at > <NUMEX TYPE="CARDINAL">.60</NUMEX>.
        Another benefit of the <ENAMEX TYPE="ORGANIZATION">GT</ENAMEX> approach is that the
        reliability <ENAMEX TYPE="SUBSTANCE">coefficient</ENAMEX> derived from the <ENAMEX TYPE="ORGANIZATION">GT</ENAMEX> analysis is
        equivalent to <ENAMEX TYPE="ORGANIZATION">Cronbach</ENAMEX>'s alpha coefficient which, for
        binary items, is equivalent to the <ENAMEX TYPE="PRODUCT">KR-20</ENAMEX> reliability
        <ENAMEX TYPE="ORGANIZATION">coefficient</ENAMEX>. The alpha coefficient is especially useful
        during test development because it gives a measure of how
        each item is contributing to the scale to which it has been
        assigned. This measure makes it easy to target items for
        editing or deletion if they are not performing well. Since
        we are ultimately interested in using the scale scores for
        our research study, the <ENAMEX TYPE="ORGANIZATION">GT</ENAMEX> measure of reliability is
        appropriate for <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>'s involving many preceptors.
        The validity of our <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> is only partially established.
        While several features support its face and content
        <ENAMEX TYPE="PERSON">validity</ENAMEX>, construct and criterion validity remain to be
        tested. Multiple refinements of <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> over the two
        <TIMEX TYPE="DATE">developmental years</TIMEX> of the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> prior to this study yielded
        broad agreement among the teaching site <ENAMEX TYPE="PER_DESC">directors</ENAMEX> that all
        <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> questions reflected essential skills that should be
        taught to and mastered by second-year <ENAMEX TYPE="PER_DESC">students</ENAMEX>. <TIMEX TYPE="TIME">Five</TIMEX>
        successive years of post-OSCE <ENAMEX TYPE="PER_DESC">student</ENAMEX> and faculty
        evaluations have endorsed the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> as a highly appropriate
        and acceptable method of education and evaluation. Finally,
        a more recent investigation supports predictive validity of
        our <ENAMEX TYPE="SUBSTANCE">OSCE</ENAMEX>. Physical diagnosis skills examined in the present
        study correlated with scores on the USMLE Step <NUMEX TYPE="CARDINAL">1</NUMEX> exam, and
        the skills that foreshadow the clinical clerkships -
        identification of abnormality and development of
        differential diagnoses - best predicted <ENAMEX TYPE="ORGANIZATION">USMLE</ENAMEX> <ENAMEX TYPE="PER_DESC">scores</ENAMEX> [ <TIMEX TYPE="DATE">42</TIMEX> ]
        .
        Variation in skill scores may be due to different OSCE
        station content. <NUMEX TYPE="CARDINAL">Three</NUMEX> of the skills drew their questions
        from a smaller number of <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>: <ENAMEX TYPE="PER_DESC">patient</ENAMEX> interaction, <NUMEX TYPE="CARDINAL">3</NUMEX>
        <ENAMEX TYPE="ORGANIZATION">stations</ENAMEX>; history-taking, <NUMEX TYPE="CARDINAL">3</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>; presentation, <NUMEX TYPE="CARDINAL">1</NUMEX>
        <ENAMEX TYPE="ORGANIZATION">station</ENAMEX>. However, <ENAMEX TYPE="PER_DESC">patient</ENAMEX> interaction and history-taking
        drew their questions from the same <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>. More
        <ENAMEX TYPE="PERSON">importantly</ENAMEX>, the remaining <NUMEX TYPE="CARDINAL">4</NUMEX> skills each drew their
        questions from <NUMEX TYPE="CARDINAL">6</NUMEX>-<NUMEX TYPE="CARDINAL">8</NUMEX> <ENAMEX TYPE="ORG_DESC">stations</ENAMEX>. For these <NUMEX TYPE="CARDINAL">4</NUMEX> skills (physical
        examination technique, physical examination knowledge,
        identification of abnormalities, and differential
        diagnosis), the range of case content is considerable and
        counters the concern that variation might be caused by case
        content rather than by <ENAMEX TYPE="PER_DESC">student</ENAMEX> performance.
        Variation in skill scores may be also due to inherent
        differences in the degree of difficulty of exam questions.
        In our exam, we did not weight OSCE questions according to
        degree of difficulty. We were not trying to create an exam
        in which all items were of equal difficulty. Instead, we
        created an <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> in which the course <ENAMEX TYPE="PER_DESC">directors</ENAMEX> considered
        all test items essential to be mastered by the <ENAMEX TYPE="PER_DESC">students</ENAMEX>.
        The results showed variation in the degree to which the
        <ENAMEX TYPE="PER_DESC">students</ENAMEX> mastered different clinical skills. Remarkable
        stability of overall scores over <TIMEX TYPE="DATE">the three years</TIMEX> of this
        study with <NUMEX TYPE="CARDINAL">three</NUMEX> different <ENAMEX TYPE="PER_DESC">cohorts</ENAMEX> of <ENAMEX TYPE="PER_DESC">students</ENAMEX> provides
        evidence that there has been no significant "teaching to
        the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX>." This finding is consistent with a prior study of
        <NUMEX TYPE="ORDINAL">fourth</NUMEX>-year <ENAMEX TYPE="PER_DESC">students</ENAMEX> [ <TIMEX TYPE="DATE">43</TIMEX> ] .
        The successful implementation of the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> at our medical
        school is relevant to all medical <ENAMEX TYPE="ORG_DESC">schools</ENAMEX> that face the
        logistical challenges posed by multiple <ENAMEX TYPE="FAC_DESC">sites</ENAMEX> and
        preceptors for <ENAMEX TYPE="PER_DESC">student</ENAMEX> training in physical diagnosis.
        Furthermore, the results from the second-year <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> reported
        here and our pre-<TIMEX TYPE="DATE">fourth year</TIMEX> OSCE [ <TIMEX TYPE="DATE">44</TIMEX> ] have been useful
        in helping to identify areas of weakness that could benefit
        from remediation prior to the start of clinical <ENAMEX TYPE="FAC_DESC">clerkships</ENAMEX>.
        This benefit is especially true for <ENAMEX TYPE="PER_DESC">students</ENAMEX> with the
        lowest performance on individual <ENAMEX TYPE="ORG_DESC">stations</ENAMEX> and skills. For
        site <ENAMEX TYPE="PER_DESC">directors</ENAMEX> and <ENAMEX TYPE="PER_DESC">faculty</ENAMEX>, the <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> has also helped
        identify those parts of the curriculum <ENAMEX TYPE="PER_DESC">students</ENAMEX> had
        difficulty mastering. Holding a second-year <ENAMEX TYPE="ORGANIZATION">OSCE</ENAMEX> prior to
        the end of a physical diagnosis course helps medical school
        faculty identify opportunities for remediation, focus the
        remaining sessions of the course, and improve future
        physical diagnosis teaching.
      
      
        Conclusions
        Objective identification of skills acquired in a
        physical diagnosis course is a necessary <NUMEX TYPE="ORDINAL">first</NUMEX> step in
        improving the quality of both the teaching and the learning
        of those skills. In our <ENAMEX TYPE="SUBSTANCE">OSCE</ENAMEX> for a second-year physical
        diagnosis course, <ENAMEX TYPE="PER_DESC">students</ENAMEX> scored higher on interpersonal
        and technical skills than on interpretive or integrative
        skills. Station scores identified specific content needing
        improvements in <ENAMEX TYPE="PER_DESC">students</ENAMEX>' integrative and organ
        system-specific skills of physical diagnosis, and in the
        teaching of these skills.
      
      
        Competing Interests
        None declared
      
    
  
