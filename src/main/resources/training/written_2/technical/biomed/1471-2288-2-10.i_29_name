
  
    
      
        Background
        <ENAMEX TYPE="ORGANIZATION">Meta</ENAMEX>-analysis has been defined as 'the statistical
        analysis of a large collection of analysis results from
        individual studies for the purpose of integrating the
        findings.' [ <ENAMEX TYPE="LAW">1</ENAMEX> ] Although there has always been some
        controversy about its validity [ <NUMEX TYPE="CARDINAL">2 3 4 5 6 7 8</NUMEX> ] ,
        <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis has become increasingly popular as the number
        of studies with similar protocols has grown. By
        systematically combining studies, one attempts to overcome
        limits of size or scope in individual studies to obtain
        more reliable information about treatment effects.
        A meta-analysis goes beyond a literature review, in
        which the results of the various studies are discussed,
        compared and perhaps tabulated, since it synthesizes the
        results of the individual studies into a new result. A
        <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis also differs from a 'pooled data' analysis
        because the summary results of the previous studies, not
        the results on individual <ENAMEX TYPE="PER_DESC">subjects</ENAMEX>, are combined for
        analysis.
        <ENAMEX TYPE="ORGANIZATION">Meta</ENAMEX>-analyses are fairly common in some fields of
        research and are relatively rare in others. In fact, a
        <TIMEX TYPE="DATE">March 2002</TIMEX> Medline search revealed <NUMEX TYPE="CARDINAL">1,610</NUMEX> articles with the
        <ENAMEX TYPE="FAC">keyword 'cancer'</ENAMEX>, and <NUMEX TYPE="CARDINAL">only 19</NUMEX> with the keyword <ENAMEX TYPE="ORGANIZATION">COPD</ENAMEX> and <NUMEX TYPE="CARDINAL">41</NUMEX>
        with the keyword 'epilepsy' among the <NUMEX TYPE="CARDINAL">9,055</NUMEX> articles
        indexed under meta-analysis. This may reflect a common
        belief that meta-analyses should be based on multiple
        clinical trials, which are very common in <ENAMEX TYPE="DISEASE">cancer</ENAMEX> studies
        and less common in other fields. However, a meta-analysis
        of small trials may provide sufficient information on
        treatment effects to avoid the delay and expense of a
        large-scale randomized clinical trial. If proper methods
        for selecting and combining studies are used, observational
        studies can also be included in a meta-analysis [ <ENAMEX TYPE="LAW">9 10 11</ENAMEX> ]
        . Guidelines for meta-analysis of observational studies
        have been published [ <TIMEX TYPE="DATE">12</TIMEX> ] . In particular, meta-analysis
        may be used for combining studies in research where
        clinical trials would not be practical or would be
        unethical.
        Because a meta-analysis does not involve human subjects
        or experimental <ENAMEX TYPE="ANIMAL">animals</ENAMEX> directly, it is often considered an
        easy study that can be done with a minimum of effort and
        little attention is often paid to details of design and
        implementation. A valid meta-analysis, however, requires
        the same careful planning as any other research study. In
        this paper, we will focus on the important design issues
        underlying a meta-analysis: formulating the study question,
        identification of research studies, collecting and
        evaluating information about these studies, and extracting
        results. Simple methods for analyzing the data once it is
        collected are described briefly.
      
      
        Methods
        
          Defining the <ENAMEX TYPE="ORGANIZATION">Objectives of the Study</ENAMEX>
          The <NUMEX TYPE="ORDINAL">first</NUMEX> step is to identify the problem. This
          includes specifying the disease or condition of interest,
          the <ENAMEX TYPE="PER_DESC">population</ENAMEX> of interest, the specific treatments or
          exposures being studied and the outcome measurements
          (efficacy, adverse reactions or both) being studied.
          Additional clinical or biological measurements of
          interest that might be potential confounders of the
          results should also be identified at this time, although
          other factors may be recognized during the evaluation or
          <ENAMEX TYPE="ORGANIZATION">data</ENAMEX> collection phase of the meta-analysis.
          The goals of the study should be defined at this
          stage. <ENAMEX TYPE="ORGANIZATION">Meta</ENAMEX>-analyses attempt to meet one or both of <NUMEX TYPE="CARDINAL">two</NUMEX>
          goals: summarizing the available data or explaining the
          variability between different studies. When the objective
          is to summarize the effects of an intervention, ideally
          all studies would have similar patient characteristics
          and the outcome measures would be consistent across
          studies. Thus, the summary measure resulting from the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis would reflect the effect of the treatment
          being studied. In practice, however, there is always
          variability between studies both in patient
          <ENAMEX TYPE="PERSON">characteristics</ENAMEX> and in outcome measures, which is, of
          course, the primary motivation for performing a formal
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis.
          Alternatively, one might attempt to model the
          variability between studies to understand why different
          studies had different results [ <NUMEX TYPE="CARDINAL">13 14</NUMEX> ] . This would
          suggest that as wide a range of studies should be
          included as possible. Frequently both objectives can be
          served in the same meta-analysis, by providing summary
          statistics of treatment or exposure effects in <ENAMEX TYPE="PER_DESC">subgroups</ENAMEX>,
          often referred to as a sensitivity analysis, and modeling
          the heterogeneity across studies as a function of patient
          characteristics. Given the amount of work involved in
          performing any meta-analysis, we recommend that a
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis attempt to meet both these goals.
        
        
          Defining the <ENAMEX TYPE="ORGANIZATION">Population of Studies Included</ENAMEX> in the
          <ENAMEX TYPE="ORGANIZATION">Meta-Analysis</ENAMEX>
          Inclusion and exclusion criteria for studies are as
          necessary in a meta-analysis as they are in clinical
          studies to safeguard against selection bias. These
          criteria need to be specified in the meta-analysis
          <ENAMEX TYPE="PERSON">protocol</ENAMEX>, just as inclusion / exclusion criteria are
          specified in a clinical protocol. The criteria should
          follow immediately from the objectives of the study. An
          analysis aimed at providing a summary result in a
          specific subgroup of subjects will necessarily have more
          restrictive criteria than <NUMEX TYPE="CARDINAL">one</NUMEX> designed to investigate
          <ENAMEX TYPE="ORGANIZATION">heterogeneity</ENAMEX>. The inclusion criteria should address at
          least <TIMEX TYPE="DATE">the following</TIMEX>.
        
        
          Type of study
          Will the analysis be restricted to randomized clinical
          trials only, or will other designs be included? In our
          opinion, trials other than RCT are allowable. As we
          mentioned in the introduction, there is some disagreement
          on this subject [ <NUMEX TYPE="CARDINAL">5 6 9 11 12 15 16</NUMEX> ] . The type of study
          may be used as a classification variable in a sensitivity
          analysis or in assessing the quality of the study as
          described below. <ENAMEX TYPE="ORGANIZATION">Olkin</ENAMEX> [ <TIMEX TYPE="DATE">14</TIMEX> ] has developed a hierarchy
          of strength of evidence based on the type of design,
          ranging from case reports (the weakest) to randomized
          trials (the strongest), with case-control studies
          somewhere in the middle. This hierarchy may serve as a
          guideline for inclusion of different designs. Example <NUMEX TYPE="CARDINAL">3</NUMEX> [
          <NUMEX TYPE="CARDINAL">17</NUMEX> ] , discussed below, shows how a valid meta-analysis
          may be based only on observational studies when clinical
          trials would not be ethical.
        
        
          Patient characteristics
          These include age, gender, ethnicity, presenting
          condition, duration of <ENAMEX TYPE="DISEASE">illness</ENAMEX>, and method of diagnosis.
          Again, this needs to reflect the goals of the study. We
          recommend that a meta-analysis be as inclusive as
          possible, e.g., you may exclude studies in <ENAMEX TYPE="PER_DESC">children</ENAMEX> if
          they are known to be different from <ENAMEX TYPE="PER_DESC">adults</ENAMEX>, but all
          studies in <ENAMEX TYPE="PER_DESC">adults</ENAMEX> should be included without regard to
          age or gender. If you limit the meta-analysis to a very
          restricted population it will probably provide little new
          information. We recommend including <ENAMEX TYPE="PER_DESC">population</ENAMEX> factors as
          <ENAMEX TYPE="ORGANIZATION">covariates</ENAMEX> in estimates of the overall effect and
          examining their effects in a sensitivity analysis.
        
        
          Treatment modalities
          Allowable treatment type, dosage, and duration of
          treatment should be addressed. Since analysis of a given
          treatment is frequently the reason for the meta-analysis,
          most meta-analyses are limited to tests of a specific
          treatment or variations within that treatment, such as
          <ENAMEX TYPE="PERSON">formulation</ENAMEX>, route of delivery, or dosage. Variations in
          treatment may be deliberately included for comparison or
          for sensitivity analysis. If controlled studies are
          included, then these criteria should specify the
          acceptable control <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>, e.g., placebo control or a
          standard treatment. If <NUMEX TYPE="CARDINAL">more than one</NUMEX> standard treatment
          can be used for the condition being studied, then the
          protocol must either define which ones will be acceptable
          or methods to address this possible source of variability
          between studies.
        
        
          Outcome measures
          Many studies have multiple outcome measures. The
          protocol for the meta-analysis should specify the outcome
          measure(s) of interest, including the allowable methods
          of measurement. For example, percent body fat may be
          measured by <ENAMEX TYPE="ORGANIZATION">DEXA</ENAMEX> scan, by underwater weighing, by
          <ENAMEX TYPE="ORGANIZATION">bioimpedance</ENAMEX> or by anthropometry. Different methods of
          <ENAMEX TYPE="PERSON">measurement</ENAMEX>, if allowed, should be accounted for in the
          analysis. When allowed, the protocol must specify whether
          every study must report all of them, any one of them, or
          <NUMEX TYPE="CARDINAL">at least one or two</NUMEX> specific ones. We recommend that the
          protocol allow <NUMEX TYPE="CARDINAL">only one or two</NUMEX> primary outcomes to focus
          the analysis and avoid the impression of a fishing
          expedition. We realize that once the studies have been
          located and evaluated, <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> are reluctant to
          neglect any information and may want to perform
          additional analyses on other outcomes. However, it is
          likely that not all studies relating to these other
          <ENAMEX TYPE="PERSON">outcomes</ENAMEX> will have been obtained since they were not the
          initial purpose of the analysis.
          An important point, sometimes neglected, is that one
          should include <NUMEX TYPE="CARDINAL">only one</NUMEX> set of results from a single
          study, even if multiple <ENAMEX TYPE="ORG_DESC">publications</ENAMEX> are available. Thus,
          it is necessary to have a method for deciding which
          paper(s) will be included. Most often it is reasonable to
          specify that this will be the latest <ENAMEX TYPE="ORG_DESC">paper</ENAMEX> published, or
          the <ENAMEX TYPE="ORG_DESC">paper</ENAMEX> with the most complete data on the outcome
          measures of interest. In any case, the decision rule
          needs to be specified in the meta-analysis protocol
          before reviewing results in the <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> so that selection
          cannot be influenced by the results.
        
        
          <ENAMEX TYPE="ORGANIZATION">Locating Studies</ENAMEX>
          Locating 
          all studies is by far the most
          difficult and the most frustrating aspect of any
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis but it is the most important step. A
          structured plan is necessary to manage the frequently
          large number of papers. Most meta-analyses begin with a
          search using the <ENAMEX TYPE="ORGANIZATION">NLM</ENAMEX> <ENAMEX TYPE="PRODUCT">Medline</ENAMEX> system. This should be
          supplemented by the use of other computerized indices,
          such as in-house research listings and reports from
          professional <ENAMEX TYPE="ORG_DESC">organizations</ENAMEX>. Properly done, this will give
          you most of the 
          published articles relating to your
          topic.
          There are several options for finding unpublished
          studies. Peer consultation, i.e. networking among your
          professional <ENAMEX TYPE="PER_DESC">colleagues</ENAMEX> and contacting specific
          <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> who are known to be active in the area can
          help identify additional studies and <ENAMEX TYPE="PER_DESC">investigators</ENAMEX>. Since
          abstracts are often not included in computer indexes, it
          is necessary to manually review special meeting issues of
          <ENAMEX TYPE="ORGANIZATION">journals</ENAMEX> from the major professional <ENAMEX TYPE="ORG_DESC">organizations</ENAMEX> in the
          <ENAMEX TYPE="PERSON">field</ENAMEX>. In addition, one might publish a request for
          information at meetings and in newsletters. References to
          'unpublished data' in published studies must be followed
          up. The <ENAMEX TYPE="ORGANIZATION">NIH</ENAMEX> and <ENAMEX TYPE="ORGANIZATION">NLM</ENAMEX> maintain registries of clinical
          trials for some <ENAMEX TYPE="DISEASE">diseases</ENAMEX>; public non-profit
          <ENAMEX TYPE="ORGANIZATION">organizations</ENAMEX>, such as the <ENAMEX TYPE="ORGANIZATION">American Diabetes Association</ENAMEX>,
          can usually supply information about trials and other
          studies that they are sponsoring. The <ENAMEX TYPE="ORGANIZATION">Cochrane Library</ENAMEX>
          contains a bibliography of controlled trials as well as
          abstracts of reviews of the effects of healthcare. The
          Internet is becoming increasingly important for
          identifying studies, using resources such as news groups
          or mailing lists.
          In meta-analysis, one is particularly concerned with
          publication bias, i.e. the effect of failing to detect
          unpublished trials. The most common reason for not
          publishing is nonsignificant or uninteresting results [
          <NUMEX TYPE="CARDINAL">16 18</NUMEX> ] . Clearly, leaving out negative studies in any
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis will substantially bias the result so that
          treatment will appear more effective than it actually is.
          Other factors associated with failure to publish include
          type of study, with clinical trials being most likely to
          be published, and funding source, with externally funded
          studies having a higher publication rate. <ENAMEX TYPE="ORGANIZATION">Olkin</ENAMEX> [ <TIMEX TYPE="DATE">14</TIMEX> ]
          has noted that the results of very large studies are
          usually published whereas the publication of small
          studies may depend on timing, with early small studies
          having a higher chance of <ENAMEX TYPE="ORG_DESC">publications</ENAMEX> than later small
          studies. Other causes of publication bias include
          language restrictions [ <NUMEX TYPE="CARDINAL">13 19</NUMEX> ] and imperfect search
          techniques. For <TIMEX TYPE="DATE">the later</TIMEX>, we recommend that
          <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> seek the support of the institutional
          <ENAMEX TYPE="PERSON">librarians</ENAMEX>. Negative studies are more likely to be
          published in 'local' <ENAMEX TYPE="ORG_DESC">journals</ENAMEX> and not in the major
          international <ENAMEX TYPE="ORG_DESC">journals</ENAMEX>, therefore restricting language to
          <ENAMEX TYPE="PERSON">English</ENAMEX> tends to exclude negative studies done in
          non-<ENAMEX TYPE="NATIONALITY">English</ENAMEX> speaking <ENAMEX TYPE="GPE_DESC">countries</ENAMEX> [ <TIMEX TYPE="DATE">19</TIMEX> ] . Unfortunately, it
          is not always possible to obtain a reliable translation
          of these <ENAMEX TYPE="ORG_DESC">papers</ENAMEX>. Decisions regarding inclusion of papers
          in a foreign language must be made before <NUMEX TYPE="CARDINAL">one</NUMEX> begins
          attempting to locate studies. Even if the results of such
          papers are not included in the meta-analysis, the
          existence of such <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> should be reported.
          We recommend that all relevant studies be listed in
          the <ENAMEX TYPE="SUBSTANCE">material</ENAMEX> and methods section or in an appendix, even
          when it was not possible to formally screen and evaluate
          them in the meta-analysis, so that the <ENAMEX TYPE="PER_DESC">reader</ENAMEX> will be
          aware of the number of studies not included in the formal
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis.
        
        
          Screening and Evaluation
          A quick review of the abstracts of the <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> will
          eliminate those that are clearly not relevant to the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis or do not meet other criteria, such as
          study design, specific <ENAMEX TYPE="PER_DESC">population</ENAMEX>, duration of treatment
          or date of the study. If the published material is just
          an abstract, there must be sufficient information to
          evaluate its quality. There must also be summary
          statistics to put into the meta-analysis, available
          either from the written material or in writing from the
          <ENAMEX TYPE="PER_DESC">investigator</ENAMEX>. It is essential that when the available
          written information is insufficient for the meta-analysis
          that strenuous efforts be made to contact the principal
          <ENAMEX TYPE="PER_DESC">investigator</ENAMEX> to obtain the needed information in order to
          reduce the effect of publication bias. This becomes even
          more important for material that has not been formally
          published, which can only be obtained from the principal
          <ENAMEX TYPE="PER_DESC">investigator</ENAMEX>.
          Assuming adequate information is available, each study
          should then be subjected to a structured review of the
          quality of the study. <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX> (see additional file: <ENAMEX TYPE="PRODUCT">Table</ENAMEX>
          <NUMEX TYPE="CARDINAL">2</NUMEX>) summarizes the major points that should be addressed
          in this evaluation. Although <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX> is a model of an
          evaluation score sheet, it has not been formally tested
          or externally validated.
          The items in part A, which address <ENAMEX TYPE="PER_DESC">sources</ENAMEX>, require
          that the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> and <ENAMEX TYPE="ORG_DESC">institutions</ENAMEX>, etc., be known. These
          questions should be answered by raters not involved in
          the assessment of the methods, who would prepare a score
          sheet for each study giving only the answers to these
          questions. To assure an unbiased review, the items in
          part B should be assessed by <ENAMEX TYPE="PER_DESC">raters</ENAMEX> who are blinded both
          to the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> and the results of the study. <ENAMEX TYPE="ORGANIZATION">Personnel</ENAMEX>
          not involved in this part of the evaluation should
          prepare copies of the <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> with the <ENAMEX TYPE="PER_DESC">sources</ENAMEX>, results
          and other information that might indicate the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> or
          outcome removed for this step in the evaluation [ <ENAMEX TYPE="LAW">7</ENAMEX> ] .
          Although an <ENAMEX TYPE="PER_DESC">investigator</ENAMEX> might feel that blinding is not
          feasible because of time or cost, lack of blinding
          potentially leads to major biases in the evaluation of
          studies and thus the extra effort is warranted [ <NUMEX TYPE="CARDINAL">4 7 20</NUMEX>
          <NUMEX TYPE="CARDINAL">21 22 23</NUMEX> ] . Failure to blind the review could lead to
          biases similar to those in a record review when subjects
          are selected by <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> who are not blinded to the
          outcomes of interest. However, there may be some studies
          that are very well known, or the research area may be so
          small, that any suitable <ENAMEX TYPE="PLANT">rater</ENAMEX> will know the <ENAMEX TYPE="PER_DESC">authors</ENAMEX>
          and/or the results of the study. When this occurs,
          efforts should still be made to blind the study and have
          the study methods rated by <ENAMEX TYPE="PER_DESC">individuals</ENAMEX> outside the area
          of interest, but with expertise in study design issues.
          Some <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> feel that the evaluation should also
          address whether the conclusions of the study are
          consistent with the data. We feel that, since the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis is based on the data and not the written
          <ENAMEX TYPE="PERSON">conclusions</ENAMEX>, that this comparison would only be
          meaningful when the conclusions are so far-fetched as to
          cast doubt on the accuracy of the entire study. Since
          this case is very rare we have not included this item in
          <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX>. If conclusions are to be evaluated, the raters
          should still be blinded as to the identity of the
          <ENAMEX TYPE="PER_DESC">investigators</ENAMEX>.
          The methods used in these 'de-identified' papers
          should be evaluated by <NUMEX TYPE="CARDINAL">at least two</NUMEX> raters, a content
          <ENAMEX TYPE="PER_DESC">expert</ENAMEX> who is knowledgeable in the subject matter and a
          <ENAMEX TYPE="ORGANIZATION">biostatistician</ENAMEX> or <ENAMEX TYPE="PER_DESC">epidemiologist</ENAMEX> who can evaluate the
          <ENAMEX TYPE="ORGANIZATION">analytic</ENAMEX> methods. We strongly recommend the use of a
          numeric quality score to summarize the results of the
          evaluation [ <ENAMEX TYPE="LAW">5 20 22 24</ENAMEX> ] . The <NUMEX TYPE="CARDINAL">two</NUMEX> blinded raters will
          create a consensus score for quality which will be
          combined with the score for <ENAMEX TYPE="PER_DESC">sources</ENAMEX> from the unblinded
          <ENAMEX TYPE="ORGANIZATION">raters</ENAMEX> to give a final score for the study. The structure
          and items for the quality score must be specified in the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis protocol and should only be modified if
          some items are missing in all studies. The score should
          be based on the items in <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX>, but may be modified to
          suit the particular application. Most of the items in
          Part A and all of the items in Part B can be answered as
          <ENAMEX TYPE="ORGANIZATION">'Yes'</ENAMEX>, 'No' or 'not applicable'. Since many of the
          criteria ask whether or not specific items of information
          are in the paper, if one of these items is not in the
          publication and is not available from the <ENAMEX TYPE="PER_DESC">investigator</ENAMEX> it
          is coded as 'No', not 'missing'. Thus, the number of 'not
          applicable' or 'missing' items should be small. For
          example, if the demographic information for some or all
          subject <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> is not available, the response to the
          <NUMEX TYPE="ORDINAL">third</NUMEX> question under "<ENAMEX TYPE="WORK_OF_ART">Study Subjects</ENAMEX>" in <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX> would be
          <ENAMEX TYPE="PERSON">'No</ENAMEX>'. If this information was not given, you might not be
          able to answer the <NUMEX TYPE="ORDINAL">first</NUMEX> question in <ENAMEX TYPE="PRODUCT">Table 2</ENAMEX> under
          "<ENAMEX TYPE="WORK_OF_ART">Controls"</ENAMEX>, which would truly be missing information. We
          recommend that this type of missing data also be coded as
          <ENAMEX TYPE="PERSON">'No</ENAMEX>'. If critical information is missing, such as summary
          statistics, the <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> should contact the <ENAMEX TYPE="PER_DESC">authors</ENAMEX>
          to try to get this information and, if it is not
          available, then the study should be excluded from the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis. The total score may be based on the sum of
          individual items by scoring <NUMEX TYPE="CARDINAL">1</NUMEX> for yes and <NUMEX TYPE="CARDINAL">0</NUMEX> for no
          (reversed when necessary for consistency) then expressing
          the total as the percent of the maximum possible. The
          latter will account for items coded as 'not applicable'.
          Alternately, the <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> may generate a summary
          score for each group of items and use either the sum or
          average of these. The former method gives equal weight to
          each item in the table, while the latter gives equal
          weight to the categories but the importance of each item
          varies with the number of items in a category.
          The choice of method may depend on the proposed use of
          the quality score, which must also be specified in the
          protocol [ <ENAMEX TYPE="LAW">5 20 22</ENAMEX> ] . There is no consensus on this
          issue in the meta-analysis literature. Quality scores can
          be used in several ways: as a cutoff, with the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis including only studies above some minimum
          score; as a weighting value, with studies with higher
          quality scores being given more weight in the analysis;
          or as a descriptive characteristic of the study, used in
          explaining study variability and heterogeneity. We
          recommend that both the score based on items and the
          summary score be computed. The latter should be used to
          define a minimum value below which a study would be
          excluded from the analysis; the former can then be used
          to rank studies into <NUMEX TYPE="CARDINAL">three</NUMEX> quality <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> as a means of
          assessing heterogeneity between studies. If the number of
          studies is very large, then <NUMEX TYPE="CARDINAL">more than 3</NUMEX> <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> may be
          used. If the number of studies is small then creating
          quality <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> is not possible and only the summary score
          need be computed. We do not recommend using the quality
          score as a weighting variable because we feel it is too
          subjective. The distribution of quality <ENAMEX TYPE="PER_DESC">scores</ENAMEX> may be
          addressed in the discussion section of the <ENAMEX TYPE="ORG_DESC">publication</ENAMEX>,
          as noted below.
          There are other examples of quality scores in the
          literature. <ENAMEX TYPE="PERSON">Chalmers</ENAMEX> [ <TIMEX TYPE="DATE">25</TIMEX> ] gives a comprehensive
          instrument for scoring a randomized clinical trial with
          detailed questions on every aspect of a trial, and
          assigns weights to the different sections. Although it is
          specifically aimed at <ENAMEX TYPE="ORGANIZATION">RCT</ENAMEX>'s, it could be adapted to other
          types of studies. Other <ENAMEX TYPE="PER_DESC">authors</ENAMEX> use greatly reduced
          versions [ <NUMEX TYPE="CARDINAL">11 22 26</NUMEX> ] . A bibliography of scales and
          <ENAMEX TYPE="ORGANIZATION">checklists</ENAMEX> is given by <ENAMEX TYPE="ORGANIZATION">Moher</ENAMEX> [ <TIMEX TYPE="DATE">27</TIMEX> ] .
        
        
          <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> Abstraction
          <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> should be abstracted onto structured forms
          designed to capture relevant information in a concise,
          focused fashion. The protocol should specify the items,
          the information to be collected for each item and the
          format for collecting the items. Detailed instructions
          for data extraction and completion of the form should be
          prepared. For example, will age be recorded as the range,
          mean and standard error, or both? If recoding or
          <ENAMEX TYPE="PERSON">estimation</ENAMEX> is required, e.g., estimates of the standard
          deviation from the range, the algorithm should be
          specified. Since there is not much consistency with
          respect to use of the standard deviation versus the
          standard error, the protocol should specify which should
          be used and how to convert from <NUMEX TYPE="CARDINAL">one</NUMEX> to the other. Other
          criteria include whether rates will be entered as
          <ENAMEX TYPE="PERSON">proportions</ENAMEX> (<NUMEX TYPE="MONEY">less than</NUMEX> or equal <NUMEX TYPE="MONEY">1</NUMEX>) or as percents,
          whether natural <ENAMEX TYPE="SUBSTANCE">logarithms</ENAMEX> or base <NUMEX TYPE="CARDINAL">10</NUMEX> logarithms are
          used, etc. If data are incomplete, this should be noted
          on the form, although often if too much data are missing
          the study will be excluded from the analysis. Some texts
          give formulas for converting <NUMEX TYPE="CARDINAL">one</NUMEX> test statistic to
          another [ <TIMEX TYPE="DATE">28</TIMEX> ] ; if these are to be used they should be
          clearly defined in the instructions for data extraction.
          Ideally <NUMEX TYPE="CARDINAL">two</NUMEX> <ENAMEX TYPE="PER_DESC">individuals</ENAMEX> should independently abstract the
          results from every study and differences resolved by
          consensus. Some <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> recommend that these
          <ENAMEX TYPE="PER_DESC">individuals</ENAMEX> be blinded to the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> of the <ENAMEX TYPE="ORG_DESC">paper</ENAMEX> [ <TIMEX TYPE="DATE">21</TIMEX> ]
          , however, if the criteria for data collection are
          objective, blinding of abstractors, although not
          essential, is still desirable.
          The data abstraction form should be headed with a
          study number, if blinding is to be preserved, or with the
          name of the study, the publication or source of data, the
          name and affiliation of the <ENAMEX TYPE="PER_DESC">investigators</ENAMEX>, and the type
          of design. There should be descriptions of the study
          <ENAMEX TYPE="ORGANIZATION">groups</ENAMEX>, including number of <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>, size of <ENAMEX TYPE="ORG_DESC">group</ENAMEX>, age,
          gender distribution, diagnoses, treatments (including
          <ENAMEX TYPE="ORGANIZATION">placebo</ENAMEX>), other treatment or descriptive variables, and
          length of treatment. The summary of the results can be
          quite extensive, including descriptive statistics for all
          <ENAMEX TYPE="ORGANIZATION">groups</ENAMEX> and all outcome measures. Differences between
          <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> in time, dosage, etc. should be included in the
          information on the data abstraction form. The test
          statistics should be identified by type, and given along
          with the p value, the sample size and the degrees of
          freedom when appropriate. Details of statistical models
          need to be given, listing other variables included in the
          model.
          Space for comments should be included. <ENAMEX TYPE="PRODUCT">Table 3</ENAMEX> (see
          additional file: <ENAMEX TYPE="PRODUCT">Table 3</ENAMEX>) is an example of a data
          collection form for a meta-analysis of a clinical trial
          with <NUMEX TYPE="CARDINAL">2</NUMEX> <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> where one outcome is a continuous variable
          and a second outcome is a proportion. We strongly
          recommend pilot testing the data abstraction form on a
          few studies before defining a final format.
        
        
          <ENAMEX TYPE="ORGANIZATION">Data Analysis</ENAMEX>
          Specific methods for data analysis in meta-analysis
          have been developed and are available in many texts and
          articles. The book by <ENAMEX TYPE="ORGANIZATION">Hedges</ENAMEX> and <ENAMEX TYPE="ORGANIZATION">Olkin</ENAMEX> [ <TIMEX TYPE="DATE">28</TIMEX> ] has been
          considered the standard text since its publication in
          <TIMEX TYPE="DATE">1985</TIMEX>. The book by <ENAMEX TYPE="PERSON">Wolf</ENAMEX> [ <TIMEX TYPE="DATE">29</TIMEX> ] is a more accessible
          reference at a basic level that gives formulas and
          procedures for simple studies. There are also many
          articles on how to do meta-analysis. The review article
          by <ENAMEX TYPE="ORGANIZATION">Fleiss</ENAMEX> [ <TIMEX TYPE="DATE">30</TIMEX> ] is reasonably accessible for a
          non-<ENAMEX TYPE="PER_DESC">mathematician</ENAMEX> who is not frightened of formulas. This
          <ENAMEX TYPE="LANGUAGE">section</ENAMEX> is intended to describe the general approach to
          the statistical analysis of the summary data that were
          collected. It is not intended to give instructions on how
          to do the actual computations. We recommend that you work
          with a <ENAMEX TYPE="PER_DESC">statistician</ENAMEX> who is knowledgeable about
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis for the formal analysis of the results.
          The simplest method is to use a weighted average of
          the effects of each study. The analysis is usually based
          on a summary statistic derived from the study, often
          referred to as the effect size and a weight, which in
          most cases is the inverse of the variance of the effect
          size and is usually related to the sample size. The Q
          statistic [ <TIMEX TYPE="DATE">28</TIMEX> ] is a test of homogeneity between
          studies. A large value of Q indicates that there is
          significant heterogeneity between studies. <ENAMEX TYPE="ORGANIZATION">Petitti</ENAMEX> [ <TIMEX TYPE="DATE">31</TIMEX> ]
          has observed that this test is conservative, and we
          recommend that the significance level for this statistic
          be set to <NUMEX TYPE="CARDINAL">0.10</NUMEX> rather than the usual <NUMEX TYPE="CARDINAL">0.05</NUMEX>.
          Some <ENAMEX TYPE="PER_DESC">analysts</ENAMEX> might try to reduce the heterogeneity by
          limiting the meta-analysis to a smaller more homogeneous
          <ENAMEX TYPE="ORGANIZATION">group</ENAMEX> of studies. However, this limits the scope of the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis and essentially throws away useful
          information. Models that incorporate and evaluate sources
          of heterogeneity are available. The standard approach is
          the random effects model developed by <ENAMEX TYPE="ORGANIZATION">DerSimonian</ENAMEX> and
          <ENAMEX TYPE="PERSON">Laird</ENAMEX> [ <TIMEX TYPE="DATE">32</TIMEX> ] and is well described in their paper. Fleiss
          [ <TIMEX TYPE="DATE">30</TIMEX> ] also includes these methods as alternative methods
          of analysis in his <ENAMEX TYPE="ORG_DESC">paper</ENAMEX>. <ENAMEX TYPE="GPE">Berlin</ENAMEX> [ <TIMEX TYPE="DATE">33</TIMEX> ] and <ENAMEX TYPE="ORGANIZATION">Biggerstaff</ENAMEX> [
          <NUMEX TYPE="CARDINAL">34</NUMEX> ] expand on these methods. There is some controversy
          about the use of these <ENAMEX TYPE="PRODUCT_DESC">models</ENAMEX>. <ENAMEX TYPE="ORGANIZATION">Villar</ENAMEX> [ <TIMEX TYPE="DATE">35</TIMEX> ] , in a study
          of <NUMEX TYPE="CARDINAL">84</NUMEX> independent meta-analyses of randomized clinical
          trials, showed that in meta-analyses where there was a
          significant value of the Q statistic, the use of random
          <ENAMEX TYPE="PRODUCT">effects</ENAMEX> <ENAMEX TYPE="PRODUCT_DESC">models</ENAMEX> showed wider confidence intervals for the
          effects in question, but also showed a larger treatment
          effect. <ENAMEX TYPE="ORGANIZATION">Petitti</ENAMEX> [ <TIMEX TYPE="DATE">31</TIMEX> ] does not see a clear rationale for
          choosing between a random or fixed effects model. The
          choice of analytic methods for any but the simplest
          situation requires input from a <ENAMEX TYPE="PER_DESC">statistician</ENAMEX> experienced
          in meta-analysis.
        
        
          Reporting and Interpretation
          The protocol should indicate how the results of the
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis will be presented. We recognize that, like
          the data analysis, this preliminary plan may be modified
          during the implementation of the study. The published
          <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis should include a table containing all
          relevant descriptive information about each of the papers
          that are included in the analysis in a table. Ideally,
          all articles reviewed would be described, but this is not
          always practical, particularly if the number is large and
          many of them are irrelevant. Effect sizes, odds ratios,
          etc are considered results and may be presented in
          summary form or displayed for individual studies.
          Graphical displays are very helpful for showing the
          dispersion of single effects. All the examples described
          in the next section have good examples of graphical
          displays.
          With respect to interpretation, we wish to emphasize
          <NUMEX TYPE="CARDINAL">two</NUMEX> points. The <NUMEX TYPE="ORDINAL">first</NUMEX> is the difference between
          statistical significance and clinical importance. Most of
          the techniques for meta-analysis will give a <ENAMEX TYPE="PRODUCT_DESC">p</ENAMEX>-value, but
          these results must be interpreted in light of the other
          characteristics of the study. The distribution of quality
          scores for the studies also should be considered when
          deciding how much emphasis to give to the results. If the
          quality scores are skewed to low values, then this should
          at least be mentioned in the discussion as a possible
          shortcoming of the meta-analysis. If the studies were
          almost all of high quality, then this gives more credence
          to the results of the meta-analysis. The <NUMEX TYPE="ORDINAL">second</NUMEX> point is
          the possible effect of unpublished studies on
          statistically significant results. Formulas for
          estimating the number of unpublished negative studies
          that would be necessary to cast doubt on the results of
          the meta-analysis have been developed [ <NUMEX TYPE="CARDINAL">36 37</NUMEX> ] .
          Obviously, if this <ENAMEX TYPE="PER_DESC">number</ENAMEX> were small, then the results of
          the meta-analysis are less credible. On the other hand if
          this number is large, the results of the meta-analysis
          are likely to be valid. We recommend that the
          investigator compute this value and include the results
          in the interpretation of the findings.
        
      
      
        Results
        
          Objectives
          The <NUMEX TYPE="ORDINAL">first</NUMEX> <NUMEX TYPE="CARDINAL">three</NUMEX> articles attempted to estimate effects
          of treatment or exposure on survival (example <NUMEX TYPE="CARDINAL">1</NUMEX>), group
          differences on outcome scores (example <NUMEX TYPE="CARDINAL">2</NUMEX>) or relative
          risk (example <NUMEX TYPE="CARDINAL">3</NUMEX>). The objective of the <NUMEX TYPE="ORDINAL">fourth</NUMEX> paper was
          to explore the effect of different approaches to study
          design on the study results. We do not address the actual
          clinical criteria used in these studies, as that is not
          relevant to our <ENAMEX TYPE="ORG_DESC">paper</ENAMEX>, but all <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> reported very
          specific criteria as to <ENAMEX TYPE="PER_DESC">population</ENAMEX>, treatment, laboratory
          methods, etc.
        
        
          Study population
          These different objectives influenced the selection of
          studies. Acceptable <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> were limited to <ENAMEX TYPE="ORGANIZATION">RCT</ENAMEX>'s in the
          <NUMEX TYPE="ORDINAL">first</NUMEX> and <NUMEX TYPE="ORDINAL">second</NUMEX> articles. The <NUMEX TYPE="ORDINAL">third</NUMEX> article was based on
          case-control and cohort studies, since randomized trials
          could not be done for this topic. All study designs were
          allowable in example 4 (the design characteristics in the
          <ENAMEX TYPE="LAW">title</ENAMEX> refer to <ENAMEX TYPE="PER_DESC">population</ENAMEX> and protocol differences, not
          the type of study). <NUMEX TYPE="CARDINAL">All four</NUMEX> meta-analyses used
          additional inclusion/exclusion criteria. The criteria in
          paper 1 addressed the subject and control treatments.
          Paper 2 required double-blind trials of <TIMEX TYPE="DATE">at least 4 weeks</TIMEX>
          duration. Paper 3 required clear differentiation of
          ischemic <ENAMEX TYPE="DISEASE">stroke</ENAMEX> from other <ENAMEX TYPE="DISEASE">strokes</ENAMEX>, and <NUMEX TYPE="CARDINAL">at least 10</NUMEX>
          subjects with a stroke. Paper <TIMEX TYPE="DATE">4</TIMEX> included all study types,
          but required that measures of association between age and
          <ENAMEX TYPE="ORGANIZATION">T</ENAMEX> levels be included. All <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> required that usable
          <ENAMEX TYPE="ORGANIZATION">data</ENAMEX> be available.
        
        
          Locating studies
          Paper identification began with a <ENAMEX TYPE="ORGANIZATION">Medline</ENAMEX> search in
          each study and all <ENAMEX TYPE="PER_DESC">authors</ENAMEX> cited review articles as a
          source of other references. The <ENAMEX TYPE="PER_DESC">authors</ENAMEX> in all articles
          said that they had contacted <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> for more data.
          We are sad to note that example <TIMEX TYPE="DATE">4</TIMEX> reported that of <NUMEX TYPE="CARDINAL">ten</NUMEX>
          <ENAMEX TYPE="PER_DESC">authors</ENAMEX> contacted, <NUMEX TYPE="CARDINAL">only one</NUMEX> replied.
        
        
          Screening and evaluation methods
          Blinding was not used consistently. The <ENAMEX TYPE="PER_DESC">authors</ENAMEX> of
          example <NUMEX TYPE="CARDINAL">1</NUMEX> were the only ones who used blinded reviewers
          in selection and evaluation. The question of blinding was
          not addressed in papers <NUMEX TYPE="CARDINAL">2 and 3</NUMEX>. Paper <ENAMEX TYPE="ORG_DESC">4</ENAMEX> reported
          blinding for the quality evaluation. All <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> reported
          developing a quality score, but the quality score in
          example <TIMEX TYPE="DATE">4</TIMEX> was only on the laboratory methods, and thus
          was not describing the overall quality of the study. In
          examples <NUMEX TYPE="CARDINAL">1 and 2</NUMEX>, the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> used the scoring system of
          <ENAMEX TYPE="PERSON">Chalmers</ENAMEX> [ <TIMEX TYPE="DATE">25</TIMEX> ] , while the others used simpler scoring
          <ENAMEX TYPE="ORGANIZATION">systems</ENAMEX> developed for the study. Examples <NUMEX TYPE="CARDINAL">1</NUMEX>, <NUMEX TYPE="CARDINAL">2 and 3</NUMEX> used
          <NUMEX TYPE="CARDINAL">two</NUMEX> raters. Examples <NUMEX TYPE="CARDINAL">1 and 2</NUMEX> required a consensus
          evaluation, but example <NUMEX TYPE="CARDINAL">3</NUMEX> used the average of the two
          <ENAMEX TYPE="ORGANIZATION">raters</ENAMEX>.
          Paper <ENAMEX TYPE="ORG_DESC">1</ENAMEX> reported the overall quality scores for each
          study included in the analyses. The <ENAMEX TYPE="PER_DESC">authors</ENAMEX> used the
          quality score to divide the studies into <NUMEX TYPE="CARDINAL">three</NUMEX> <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> and
          then compared the pooled relative risk in the three
          <ENAMEX TYPE="ORG_DESC">groups</ENAMEX>. In paper <NUMEX TYPE="CARDINAL">2</NUMEX>, the <ENAMEX TYPE="PER_DESC">authors</ENAMEX> tested the effect of
          quality scores by comparing results in studies with
          scores above and below the median. Paper <ENAMEX TYPE="ORG_DESC">3</ENAMEX> did not
          describe any quality score and in paper <NUMEX TYPE="MONEY">4</NUMEX> a score was
          developed for laboratory methods which was used for
          descriptive information only.
        
        
          <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> abstraction
          Although all the articles reported or implied
          standardized data extraction, none of them provided
          examples or description of the format. Paper <ENAMEX TYPE="ORG_DESC">1</ENAMEX> reported
          using <NUMEX TYPE="CARDINAL">two</NUMEX> blinded raters for data abstraction, but the
          others did not mention blinding at this point.
        
        
          <ENAMEX TYPE="ORGANIZATION">Data</ENAMEX> analysis
          Examples <ENAMEX TYPE="CONTACT_INFO">1-3</ENAMEX> used weighted estimates of effect size to
          estimate an overall effect. In example <TIMEX TYPE="DATE">1</TIMEX>, the
          <ENAMEX TYPE="PER_DESC">investigators</ENAMEX> computed survival statistics and odds
          ratios for response and used the random effects models [
          <NUMEX TYPE="CARDINAL">32</NUMEX> ] to analyze the data. We note that in this paper the
          actual survival statistics had to be estimated from
          summary data for many of the studies. The simplest
          analysis was in example <TIMEX TYPE="DATE">2</TIMEX>, where weighted estimates of
          the differences between treated and untreated <ENAMEX TYPE="ORG_DESC">groups</ENAMEX> were
          computed for pain and disability outcomes. In example <ENAMEX TYPE="CONTACT_INFO">2,</ENAMEX>
          tests for heterogeneity were significant when all the
          studies were included, but became non-significant when
          <NUMEX TYPE="CARDINAL">one</NUMEX> study was excluded. <ENAMEX TYPE="ORGANIZATION">Subanalyses</ENAMEX> in example <NUMEX TYPE="CARDINAL">3</NUMEX> looked
          at the contributions of other factors, such as smoking
          and <ENAMEX TYPE="SUBSTANCE">alcohol</ENAMEX> to heterogeneity. The analysis in example 4
          focused on differences between the testosterone-age
          correlation in different <ENAMEX TYPE="PER_DESC">patient groups</ENAMEX> using visual
          display and multiple regression methods.
        
        
          Reporting and interpretation
          All <ENAMEX TYPE="ORG_DESC">papers</ENAMEX> gave details of all the studies that were
          included. All examples made good use of graphic display.
          Examples <ENAMEX TYPE="CONTACT_INFO">1-3</ENAMEX> included plots of the effect size for the
          selected studies, while example <NUMEX TYPE="CARDINAL">4</NUMEX> presented comparison
          plots of the regression lines for testosterone on <TIMEX TYPE="DATE">age</TIMEX> for
          different breakdowns of population characteristics or
          <NUMEX TYPE="CARDINAL">sampling</NUMEX> times.
        
      
      
        Conclusion
        In this paper we have addressed the procedures for
        performing a meta-analysis, focusing primarily on the steps
        before data analysis. <ENAMEX TYPE="ORGANIZATION">Meta</ENAMEX>-analysis cannot be thought of as
        a quick and easy way to pull a lot of studies together and
        come up with a publication, but like any other study,
        requires an appreciable investment of time in planning and
        implementation. As with any scientific procedure, there are
        <ENAMEX TYPE="FAC_DESC">areas</ENAMEX> of controversy. A primary one is the inclusion of
        studies other than <ENAMEX TYPE="ORGANIZATION">RCT</ENAMEX>'s. Although this has become more
        common in <TIMEX TYPE="DATE">the past few years</TIMEX>, it is still controversial. In
        example <TIMEX TYPE="DATE">3</TIMEX>, there were no <ENAMEX TYPE="ORGANIZATION">RCT</ENAMEX>'s for this subject, although
        there had been many observational studies. It is important
        that, however you decide, you have a good reason for your
        choice.
        Another area of controversy is in the homogeneity of the
        studies. We stated previously that when the purpose of a
        <ENAMEX TYPE="ORGANIZATION">meta</ENAMEX>-analysis is to provide estimates of specific effects,
        then the criteria for inclusion would be more restrictive
        than if the objective were to model <ENAMEX TYPE="PER_DESC">sources</ENAMEX> of variability.
        In practice, most meta-analyses combine both objectives.
        Even if the primary objective is simple estimates, there
        are population effects that should be investigated and
        discussed. <NUMEX TYPE="CARDINAL">One</NUMEX> of the benefits of meta-analysis is that it
        may be used to extend conclusions beyond the frequently
        <ENAMEX TYPE="ORGANIZATION">limited</ENAMEX> <ENAMEX TYPE="PER_DESC">populations</ENAMEX> that are included in a single study.
        Moreover, given the effort that goes into identifying and
        evaluating papers, ignoring or rejecting valuable
        information is wasteful. <ENAMEX TYPE="ORGANIZATION">Dickersin</ENAMEX> and others [ <NUMEX TYPE="CARDINAL">18 34</NUMEX> ]
        point out that heterogeneity is not all bad. It improves
        the generalizability of the results of the meta-analysis.
        It may help to point out factors that influence the results
        of the outcome that were not observable in individual
        trials. If the effect is consistent even with discrepant
        studies, it strengthens the case for the causality of the
        treatment. If a meta-analysis is performed prior to
        beginning a new study, then heterogeneity may help the
        investigator improve his design by incorporating an
        understanding of these other factors.
        We mention here that there is some leeway to modify your
        goals once original studies are reviewed, since only then
        will you know the extent of the data and which variables,
        other than the primary effect, have been measured. For
        example, you may find that there is an obvious grouping of
        study <ENAMEX TYPE="PER_DESC">populations</ENAMEX> by age or ethnicity, and decide to
        investigate those effects. Such modifications should, of
        course, be restricted to observation of the available data
        and should not be based on the results of preliminary
        analysis.
        In summary, a meta-analysis is an important and valuable
        tool for summarizing data from multiple studies. However,
        it is not an easy task and requires careful thought and
        planning to provide accurate and useful information.
      
      
        Competing Interests
        None declared.
      
      
        <ENAMEX TYPE="PER_DESC">Authors</ENAMEX>' Contributions
        <ENAMEX TYPE="PERSON">Nancy G. Berman</ENAMEX> and <ENAMEX TYPE="PERSON">Robert A. Parker</ENAMEX> collaborated on the
        <ENAMEX TYPE="ORGANIZATION">conceptualization</ENAMEX> and writing of this <ENAMEX TYPE="ORG_DESC">paper</ENAMEX>. Both <ENAMEX TYPE="PER_DESC">authors</ENAMEX>
        read and approved the final manuscript.
      
    
  
